#!/usr/bin/env python3
"""
é«˜çº§Aprioriè§„åˆ™æ ‡ç­¾åˆ†ç±»æ¼”ç¤º
å±•ç¤ºæ›´å¤æ‚çš„è§„å¾‹å’Œå¼‚å¸¸æ£€æµ‹
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / 'src'))

try:
    from analysis.project_data_miner import ProjectDataMiner
    ANALYSIS_AVAILABLE = True
except ImportError as e:
    print(f"åˆ†ææ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    ANALYSIS_AVAILABLE = False

# å°è¯•å¯¼å…¥æŠ¥å‘Šç”Ÿæˆå™¨
try:
    from visualization.pdf_report_generator import ProjectMiningPDFReporter
    from visualization.html_report_generator import ProjectMiningHTMLReporter
    REPORT_GENERATORS_AVAILABLE = True
    print("âœ… æŠ¥å‘Šç”Ÿæˆå™¨åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå™¨ä¸å¯ç”¨: {e}")
    REPORT_GENERATORS_AVAILABLE = False


def create_advanced_project_data():
    """åˆ›å»ºåŒ…å«æ›´å¤æ‚è§„å¾‹çš„é¡¹ç›®æ•°æ®"""
    print("åˆ›å»ºé«˜çº§é¡¹ç›®æ•°æ®...")
    
    np.random.seed(42)
    n_projects = 200
    
    project_types = ['Webåº”ç”¨', 'ç§»åŠ¨åº”ç”¨', 'APIæœåŠ¡', 'æ¡Œé¢åº”ç”¨']
    project_levels = ['P0', 'P1', 'P2']
    product_lines = ['ç”µå•†å¹³å°', 'é‡‘èæœåŠ¡', 'ç¤¾äº¤åª’ä½“']
    organizations = ['è´¨é‡éƒ¨é—¨A', 'è´¨é‡éƒ¨é—¨B', 'å¤–åŒ…å›¢é˜ŸC']
    
    data = []
    
    for i in range(n_projects):
        project_type = np.random.choice(project_types)
        project_level = np.random.choice(project_levels)
        product_line = np.random.choice(product_lines)
        organization = np.random.choice(organizations)
        
        # åˆ›å»ºæ›´æ˜ç¡®çš„å…³è”è§„å¾‹
        
        # è§„å¾‹1: Webåº”ç”¨ + P0çº§åˆ« -> è´¨é‡éƒ¨é—¨A (80%æ¦‚ç‡)
        if project_type == 'Webåº”ç”¨' and project_level == 'P0':
            if np.random.random() < 0.2:  # 20%æ¦‚ç‡è¿åè§„å¾‹
                organization = np.random.choice(['è´¨é‡éƒ¨é—¨B', 'å¤–åŒ…å›¢é˜ŸC'])
            else:
                organization = 'è´¨é‡éƒ¨é—¨A'
        
        # è§„å¾‹2: é‡‘èæœåŠ¡ -> P0çº§åˆ« (75%æ¦‚ç‡)
        if product_line == 'é‡‘èæœåŠ¡':
            if np.random.random() < 0.25:  # 25%æ¦‚ç‡è¿åè§„å¾‹
                project_level = np.random.choice(['P1', 'P2'])
            else:
                project_level = 'P0'
        
        # è§„å¾‹3: å¤–åŒ…å›¢é˜ŸC -> ç§»åŠ¨åº”ç”¨ (70%æ¦‚ç‡)
        if organization == 'å¤–åŒ…å›¢é˜ŸC':
            if np.random.random() < 0.3:  # 30%æ¦‚ç‡è¿åè§„å¾‹
                project_type = np.random.choice(['Webåº”ç”¨', 'APIæœåŠ¡', 'æ¡Œé¢åº”ç”¨'])
            else:
                project_type = 'ç§»åŠ¨åº”ç”¨'
        
        # è§„å¾‹4: ç¤¾äº¤åª’ä½“ + APIæœåŠ¡ -> è´¨é‡éƒ¨é—¨B (85%æ¦‚ç‡)
        if product_line == 'ç¤¾äº¤åª’ä½“' and project_type == 'APIæœåŠ¡':
            if np.random.random() < 0.15:  # 15%æ¦‚ç‡è¿åè§„å¾‹
                organization = np.random.choice(['è´¨é‡éƒ¨é—¨A', 'å¤–åŒ…å›¢é˜ŸC'])
            else:
                organization = 'è´¨é‡éƒ¨é—¨B'
        
        # åŸºç¡€æŒ‡æ ‡è®¡ç®—ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        level_multiplier = {'P0': 2.5, 'P1': 2.0, 'P2': 1.5}[project_level]
        
        executed_cases = max(20, int(np.random.normal(100 * level_multiplier, 30)))
        automation_rate = np.random.uniform(0.3, 0.8)
        automated_cases = int(executed_cases * automation_rate)
        related_bugs = max(1, int(executed_cases * np.random.uniform(0.03, 0.1)))
        effort_hours = max(20, int(executed_cases * np.random.uniform(0.4, 0.8)))
        
        data.append({
            'é¡¹ç›®åç§°': f'é¡¹ç›®_{product_line}_{project_type}_{i+1:03d}',
            'é¡¹ç›®ç¼–å·': f'PRJ-{i+1:04d}',
            'é¡¹ç›®ç±»å‹': project_type,
            'é¡¹ç›®çº§åˆ«': project_level,
            'äº§å“çº¿': product_line,
            'äº§å“ç±»å‹': np.random.choice(['å‰ç«¯', 'åç«¯', 'å…¨æ ˆ']),
            'æµ‹è¯•è´Ÿè´£äºº': f'æµ‹è¯•å‘˜{np.random.randint(1, 11):02d}',
            'æµ‹è¯•è´Ÿè´£äººæ‰€å±ç»„ç»‡æ¶æ„': organization,
            'æ‰§è¡Œç”¨ä¾‹æ•°': executed_cases,
            'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°': automated_cases,
            'å…³è”ç¼ºé™·': related_bugs,
            'æŠ•å…¥å·¥æ—¶': effort_hours
        })
    
    df = pd.DataFrame(data)
    
    # ä¿å­˜æ•°æ®
    output_file = 'advanced_project_data.xlsx'
    df.to_excel(output_file, index=False)
    print(f"é«˜çº§æµ‹è¯•æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    return df


def run_advanced_demo():
    """è¿è¡Œé«˜çº§æ¼”ç¤º"""
    print("\n" + "=" * 80)
    print("é«˜çº§Aprioriå…³è”è§„åˆ™æ•°æ®æ ‡ç­¾åˆ†ç±»æ¼”ç¤º")
    print("=" * 80)
    
    if not ANALYSIS_AVAILABLE:
        print("åˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–")
        return
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    project_data = create_advanced_project_data()
    
    # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
    print("\n1. æ•°æ®æ¦‚è§ˆ:")
    print(f"   æ€»é¡¹ç›®æ•°: {len(project_data)}")
    print(f"   é¡¹ç›®ç±»å‹åˆ†å¸ƒ: {dict(project_data['é¡¹ç›®ç±»å‹'].value_counts())}")
    print(f"   é¡¹ç›®çº§åˆ«åˆ†å¸ƒ: {dict(project_data['é¡¹ç›®çº§åˆ«'].value_counts())}")
    print(f"   äº§å“çº¿åˆ†å¸ƒ: {dict(project_data['äº§å“çº¿'].value_counts())}")
    print(f"   ç»„ç»‡åˆ†å¸ƒ: {dict(project_data['æµ‹è¯•è´Ÿè´£äººæ‰€å±ç»„ç»‡æ¶æ„'].value_counts())}")
    
    # åˆå§‹åŒ–æŒ–æ˜å™¨ï¼ˆä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼‰
    config = {
        'min_support': 0.02,     # æ›´ä½çš„æ”¯æŒåº¦é˜ˆå€¼
        'min_confidence': 0.5,   # ä¸­ç­‰ç½®ä¿¡åº¦
        'min_lift': 1.1,         # æ›´ä½çš„æå‡åº¦
        'correlation_threshold': 0.5
    }
    
    print(f"\n2. åˆå§‹åŒ–æŒ–æ˜å™¨é…ç½®: {config}")
    
    miner = ProjectDataMiner(config)
    
    # æ‰§è¡Œå…³è”è§„åˆ™æŒ–æ˜å’Œæ ‡ç­¾åˆ†ç±»
    print(f"\n3. æ‰§è¡Œå…³è”è§„åˆ™æŒ–æ˜...")
    results = miner.discover_project_associations(project_data)
    
    # æŸ¥çœ‹å‘ç°çš„å…³è”è§„åˆ™
    association_rules = results.get('categorical_associations', {}).get('association_rules', [])
    print(f"\n4. å‘ç°çš„å…³è”è§„åˆ™æ•°é‡: {len(association_rules)}")
    
    if association_rules:
        print("\n   å…³è”è§„åˆ™è¯¦æƒ…:")
        for i, rule in enumerate(association_rules, 1):
            antecedents = ' & '.join(rule.get('antecedents', []))
            consequents = ' & '.join(rule.get('consequents', []))
            confidence = rule.get('confidence', 0)
            support = rule.get('support', 0)
            lift = rule.get('lift', 1)
            
            print(f"     {i}. {antecedents} => {consequents}")
            print(f"        ç½®ä¿¡åº¦: {confidence:.3f}, æ”¯æŒåº¦: {support:.3f}, æå‡åº¦: {lift:.3f}")
    
    # æŸ¥çœ‹æ ‡ç­¾åˆ†ç±»ç»“æœ
    labeled_data = results.get('labeled_data')
    if labeled_data is not None:
        print(f"\n5. æ•°æ®æ ‡ç­¾åˆ†ç±»ç»“æœ:")
        
        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        category_counts = labeled_data['data_category'].value_counts()
        print(f"   æ•°æ®åˆ†ç±»ç»Ÿè®¡:")
        for category, count in category_counts.items():
            print(f"     {category}: {count} é¡¹ ({count/len(labeled_data):.1%})")
        
        # æ˜¾ç¤ºè¿åè§„åˆ™çš„é¡¹ç›®
        violation_data = labeled_data[labeled_data['rule_violations'] != '']
        if len(violation_data) > 0:
            print(f"\n6. è¿åè§„åˆ™çš„é¡¹ç›® ({len(violation_data)} é¡¹):")
            
            # æ˜¾ç¤ºå‰5ä¸ªè¿åè§„åˆ™çš„é¡¹ç›®
            violation_sample = violation_data[[
                'project_name', 'project_type', 'project_level', 
                'product_line', 'test_owner_org', 'rule_violations', 
                'anomaly_flags', 'anomaly_score'
            ]].head(5)
            
            for idx, row in violation_sample.iterrows():
                print(f"\n     é¡¹ç›®: {row['project_name']}")
                print(f"     ç‰¹å¾: {row['project_type']}, {row['project_level']}, {row['product_line']}, {row['test_owner_org']}")
                print(f"     è¿åè§„åˆ™: {row['rule_violations']}")
                print(f"     å¼‚å¸¸æ ‡è®°: {row['anomaly_flags']}")
                print(f"     å¼‚å¸¸è¯„åˆ†: {row['anomaly_score']:.3f}")
        
        # è§„åˆ™éµå¾ªç»Ÿè®¡
        rule_compliance_report = results.get('rule_compliance_report', {})
        if 'rule_details' in rule_compliance_report:
            print(f"\n7. è§„åˆ™éµå¾ªç»Ÿè®¡:")
            rule_details = rule_compliance_report['rule_details']
            
            for rule_stat in rule_details:
                print(f"\n     è§„åˆ™: {rule_stat['antecedents']} => {rule_stat['consequents']}")
                print(f"     æœŸæœ›ç½®ä¿¡åº¦: {rule_stat['expected_confidence']:.3f}")
                print(f"     å®é™…ç½®ä¿¡åº¦: {rule_stat['actual_confidence']:.3f}")
                print(f"     ç¬¦åˆå‰ç½®æ¡ä»¶: {rule_stat['antecedent_count']} é¡¹")
                print(f"     å®Œå…¨ç¬¦åˆè§„åˆ™: {rule_stat['complete_count']} é¡¹")
                print(f"     è¿åè§„åˆ™: {rule_stat['violation_count']} é¡¹")
                print(f"     è¿åç‡: {rule_stat['violation_rate']:.1%}")
        
        # å¼‚å¸¸æ¨¡å¼åˆ†æ
        anomaly_patterns = results.get('anomaly_patterns', {})
        if 'common_violation_patterns' in anomaly_patterns:
            violation_patterns = anomaly_patterns['common_violation_patterns']
            if violation_patterns:
                print(f"\n8. å¸¸è§è¿åæ¨¡å¼:")
                for pattern in violation_patterns:
                    print(f"     æ¨¡å¼: {pattern['pattern']}")
                    print(f"     å‡ºç°æ¬¡æ•°: {pattern['count']}, æ¯”ä¾‹: {pattern['rate']:.1%}")
        
        return labeled_data, results
    
    return None, results


def analyze_rule_effectiveness(labeled_data: pd.DataFrame, results: Dict):
    """åˆ†æè§„åˆ™æœ‰æ•ˆæ€§"""
    print("\n" + "=" * 80)
    print("è§„åˆ™æœ‰æ•ˆæ€§åˆ†æ")
    print("=" * 80)
    
    rule_compliance_report = results.get('rule_compliance_report', {})
    
    if 'summary' in rule_compliance_report:
        summary = rule_compliance_report['summary']
        
        # é«˜è¿åç‡è§„åˆ™
        high_violation_rules = summary.get('high_violation_rules', [])
        if high_violation_rules:
            print(f"\n1. é«˜è¿åç‡è§„åˆ™ ({len(high_violation_rules)} ä¸ª):")
            for rule in high_violation_rules:
                print(f"   è§„åˆ™: {rule['antecedents']} => {rule['consequents']}")
                print(f"   è¿åç‡: {rule['violation_rate']:.1%}")
        
        # ä½ç½®ä¿¡åº¦è§„åˆ™
        low_confidence_rules = summary.get('low_confidence_rules', [])
        if low_confidence_rules:
            print(f"\n2. ä½ç½®ä¿¡åº¦è§„åˆ™ ({len(low_confidence_rules)} ä¸ª):")
            for rule in low_confidence_rules:
                print(f"   è§„åˆ™: {rule['rule_name']}")
                print(f"   æœŸæœ›ç½®ä¿¡åº¦: {rule['expected_confidence']:.3f}")
                print(f"   å®é™…ç½®ä¿¡åº¦: {rule['actual_confidence']:.3f}")
                print(f"   ç½®ä¿¡åº¦å·®è·: {rule['confidence_gap']:.3f}")
        
        # æœ‰æ•ˆè§„åˆ™
        effective_rules = summary.get('effective_rules', [])
        if effective_rules:
            print(f"\n3. æœ‰æ•ˆè§„åˆ™ ({len(effective_rules)} ä¸ª):")
            for rule in effective_rules:
                print(f"   è§„åˆ™: {rule['rule_name']}")
                print(f"   ç½®ä¿¡åº¦: {rule['confidence']:.3f}")
                print(f"   æ”¯æŒåº¦: {rule['support']:.3f}")
    
    # æ€»ä½“è¿åæƒ…å†µåˆ†æ
    if labeled_data is not None:
        violation_data = labeled_data[labeled_data['rule_violations'] != '']
        total_violations = len(violation_data)
        violation_rate = total_violations / len(labeled_data)
        
        print(f"\n4. æ€»ä½“è¿åæƒ…å†µ:")
        print(f"   è¿åè§„åˆ™çš„é¡¹ç›®æ•°: {total_violations}")
        print(f"   æ€»ä½“è¿åç‡: {violation_rate:.1%}")
        
        if violation_rate > 0.15:
            print(f"   è¯„ä¼°: è¿åç‡è¾ƒé«˜ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨")
        elif violation_rate > 0.05:
            print(f"   è¯„ä¼°: è¿åç‡é€‚ä¸­ï¼Œæœ‰æ”¹è¿›ç©ºé—´")
        else:
            print(f"   è¯„ä¼°: è¿åç‡è¾ƒä½ï¼Œè§„åˆ™éµå¾ªè‰¯å¥½")


def convert_results_for_reporting(labeled_data: pd.DataFrame, 
                                analysis_results: Dict, 
                                project_data: pd.DataFrame) -> Dict[str, Any]:
    """å°†åˆ†æç»“æœè½¬æ¢ä¸ºæŠ¥å‘Šç”Ÿæˆå™¨æ‰€éœ€çš„æ ¼å¼"""
    
    # ç»Ÿè®¡é¡¹ç›®åˆ†å¸ƒ
    categorical_distributions = {}
    for col in ['é¡¹ç›®ç±»å‹', 'é¡¹ç›®çº§åˆ«', 'äº§å“çº¿', 'æµ‹è¯•è´Ÿè´£äººæ‰€å±ç»„ç»‡æ¶æ„']:
        if col in project_data.columns:
            categorical_distributions[col] = dict(project_data[col].value_counts())
    
    # æ•°å€¼å­—æ®µç»Ÿè®¡
    numerical_columns = ['æ‰§è¡Œç”¨ä¾‹æ•°', 'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°', 'å…³è”ç¼ºé™·', 'æŠ•å…¥å·¥æ—¶']
    numerical_stats = {}
    for col in numerical_columns:
        if col in project_data.columns:
            numerical_stats[col] = {
                'mean': float(project_data[col].mean()),
                'median': float(project_data[col].median()),
                'std': float(project_data[col].std()),
                'min': int(project_data[col].min()),
                'max': int(project_data[col].max())
            }
    
    # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    numerical_data = project_data[numerical_columns].select_dtypes(include=[np.number])
    correlation_matrix = None
    if len(numerical_data.columns) > 1:
        correlation_matrix = numerical_data.corr()
    
    # å¼ºç›¸å…³æ€§å…³ç³»
    strong_correlations = []
    if correlation_matrix is not None:
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_value = correlation_matrix.iloc[i, j]
                if abs(corr_value) > 0.6:  # å¼ºç›¸å…³æ€§é˜ˆå€¼
                    strong_correlations.append({
                        'field1': correlation_matrix.columns[i],
                        'field2': correlation_matrix.columns[j],
                        'correlation': corr_value
                    })
    
    # è´¨é‡æŒ‡æ ‡è®¡ç®—
    total_projects = len(project_data)
    avg_automation_rate = (project_data['è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°'] / project_data['æ‰§è¡Œç”¨ä¾‹æ•°']).mean()
    avg_defect_density = (project_data['å…³è”ç¼ºé™·'] / project_data['æ‰§è¡Œç”¨ä¾‹æ•°']).mean()
    avg_test_efficiency = (project_data['æ‰§è¡Œç”¨ä¾‹æ•°'] / project_data['æŠ•å…¥å·¥æ—¶']).mean()
    
    # é«˜è´¨é‡é¡¹ç›®ç»Ÿè®¡
    automation_rates = project_data['è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°'] / project_data['æ‰§è¡Œç”¨ä¾‹æ•°']
    defect_densities = project_data['å…³è”ç¼ºé™·'] / project_data['æ‰§è¡Œç”¨ä¾‹æ•°']
    test_efficiencies = project_data['æ‰§è¡Œç”¨ä¾‹æ•°'] / project_data['æŠ•å…¥å·¥æ—¶']
    
    high_automation_projects = len(automation_rates[automation_rates > 0.7])
    low_defect_projects = len(defect_densities[defect_densities < 0.05])
    high_efficiency_projects = len(test_efficiencies[test_efficiencies > 2.0])
    
    quality_metrics = {
        'avg_automation_rate': avg_automation_rate,
        'avg_defect_density': avg_defect_density,
        'avg_test_efficiency': avg_test_efficiency,
        'high_automation_projects': high_automation_projects,
        'low_defect_projects': low_defect_projects,
        'high_efficiency_projects': high_efficiency_projects
    }
    
    # å…³é”®å‘ç°
    key_findings = [
        f"å…±åˆ†æäº†{total_projects}ä¸ªé¡¹ç›®çš„æµ‹è¯•æ•°æ®ï¼Œæ¶‰åŠå¤šç§é¡¹ç›®ç±»å‹",
        f"å‘ç°äº†{len(analysis_results.get('categorical_associations', {}).get('association_rules', []))}ä¸ªå…³è”è§„åˆ™",
        f"è¯†åˆ«å‡º{len(labeled_data[labeled_data['rule_violations'] != ''])}ä¸ªè¿åè§„åˆ™çš„å¼‚å¸¸é¡¹ç›®",
        f"å¹³å‡è‡ªåŠ¨åŒ–ç‡ä¸º{avg_automation_rate:.1%}ï¼Œå­˜åœ¨æ”¹è¿›ç©ºé—´",
        f"ä¸åŒç»„ç»‡é—´çš„æµ‹è¯•æ•ˆç‡å­˜åœ¨æ˜¾è‘—å·®å¼‚"
    ]
    
    # ç»“è®ºå’Œå»ºè®®
    conclusions = [
        "é¡¹ç›®æ•°æ®åˆ†ææ˜¾ç¤ºäº†ä¸åŒç±»å‹ã€çº§åˆ«é¡¹ç›®çš„æ˜¾è‘—ç‰¹å¾å·®å¼‚",
        "é€šè¿‡Aprioriç®—æ³•æˆåŠŸå‘ç°äº†å¤šä¸ªå…·æœ‰å®é™…æ„ä¹‰çš„å…³è”è§„åˆ™",
        "è¿åè§„åˆ™çš„é¡¹ç›®åœ¨ç‰¹å®šç»„åˆæ¡ä»¶ä¸‹å‡ºç°ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨",
        "ç»„ç»‡é—´ç»©æ•ˆå­˜åœ¨å·®å¼‚ï¼Œå»ºè®®åŠ å¼ºæœ€ä½³å®è·µåˆ†äº«"
    ]
    
    recommendations = [
        "å»ºç«‹åŸºäºå…³è”è§„åˆ™çš„é¡¹ç›®è´¨é‡é¢„è­¦æœºåˆ¶",
        "å¯¹è¿åè§„åˆ™çš„é¡¹ç›®è¿›è¡Œé‡ç‚¹å®¡æŸ¥å’Œæ•´æ”¹",
        "ä¼˜åŒ–ç»„ç»‡é—´çš„æµ‹è¯•æµç¨‹æ ‡å‡†åŒ–å’ŒçŸ¥è¯†åˆ†äº«",
        "å®šæœŸè¿›è¡Œå…³è”è§„åˆ™æŒ–æ˜ï¼ŒæŒç»­ä¼˜åŒ–æµ‹è¯•ç®¡ç†ç­–ç•¥",
        "å»ºç«‹é¡¹ç›®é£é™©è¯„ä¼°æ¨¡å‹ï¼Œæå‰è¯†åˆ«é«˜é£é™©é¡¹ç›®"
    ]
    
    # æ„å»ºæŠ¥å‘Šæ•°æ®ç»“æ„
    report_data = {
        'total_projects': total_projects,
        'categorical_distributions': categorical_distributions,
        'numerical_statistics': numerical_stats,
        'correlation_matrix': correlation_matrix,
        'strong_correlations': strong_correlations,
        'quality_metrics': quality_metrics,
        'key_findings': key_findings,
        'conclusions': conclusions,
        'recommendations': recommendations,
        'labeled_data': labeled_data,
        'analysis_results': analysis_results
    }
    
    return report_data


def generate_reports(labeled_data: pd.DataFrame, 
                   analysis_results: Dict, 
                   project_data: pd.DataFrame) -> Dict[str, str]:
    """ç”ŸæˆPDFå’ŒHTMLæŠ¥å‘Š"""
    
    if not REPORT_GENERATORS_AVAILABLE:
        print("âš ï¸ æŠ¥å‘Šç”Ÿæˆå™¨ä¸å¯ç”¨ï¼Œè·³è¿‡æŠ¥å‘Šç”Ÿæˆ")
        return {}
    
    print("\n" + "=" * 80)
    print("ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    # è½¬æ¢æ•°æ®æ ¼å¼
    print("è½¬æ¢æ•°æ®æ ¼å¼...")
    report_data = convert_results_for_reporting(labeled_data, analysis_results, project_data)
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    reports_dir = Path('reports')
    reports_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    generated_files = {}
    
    try:
        # ç”ŸæˆPDFæŠ¥å‘Š
        print("ç”ŸæˆPDFæŠ¥å‘Š...")
        pdf_reporter = ProjectMiningPDFReporter()
        pdf_path = f"reports/advanced_rule_labeling_report_{timestamp}.pdf"
        pdf_file = pdf_reporter.generate_project_mining_report(report_data, pdf_path)
        generated_files['pdf'] = pdf_file
        
    except Exception as e:
        print(f"âš ï¸ PDFæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
    
    try:
        # ç”ŸæˆHTMLæŠ¥å‘Š
        print("ç”ŸæˆHTMLæŠ¥å‘Š...")
        html_reporter = ProjectMiningHTMLReporter()
        html_path = f"reports/advanced_rule_labeling_report_{timestamp}.html"
        html_file = html_reporter.generate_project_mining_html_report(report_data, html_path)
        generated_files['html'] = html_file
        
    except Exception as e:
        print(f"âš ï¸ HTMLæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
    
    if generated_files:
        print("\nâœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        print("\nç”Ÿæˆçš„æ–‡ä»¶:")
        for report_type, file_path in generated_files.items():
            print(f"  ğŸ“„ {report_type.upper()}æŠ¥å‘Š: {file_path}")
    else:
        print("âš ï¸ æœªèƒ½ç”Ÿæˆä»»ä½•æŠ¥å‘Š")
    
    return generated_files


def main():
    """ä¸»å‡½æ•°"""
    print("é«˜çº§Aprioriå…³è”è§„åˆ™æ•°æ®æ ‡ç­¾åˆ†ç±»æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # è¿è¡Œé«˜çº§æ¼”ç¤º
        labeled_data, results = run_advanced_demo()
        
        if labeled_data is not None:
            # åˆ†æè§„åˆ™æœ‰æ•ˆæ€§
            analyze_rule_effectiveness(labeled_data, results)
            
            # ç”ŸæˆæŠ¥å‘Š
            project_data = pd.read_excel('advanced_project_data.xlsx')
            generated_files = generate_reports(labeled_data, results, project_data)
        
        print("\n" + "=" * 60)
        print("é«˜çº§æ¼”ç¤ºå®Œæˆï¼")
        print("\nå…³é”®åŠŸèƒ½è¯´æ˜:")
        print("1. å‘ç°äº†å¤šä¸ªå…·æœ‰å®é™…æ„ä¹‰çš„å…³è”è§„åˆ™")
        print("2. æˆåŠŸè¯†åˆ«äº†è¿åè§„åˆ™çš„å¼‚å¸¸é¡¹ç›®")
        print("3. å¯¹ç¬¦åˆå‰ç½®æ¡ä»¶ä½†ä¸ç¬¦åˆåç½®æ¡ä»¶çš„æ•°æ®è¿›è¡Œäº†æ ‡è®°")
        print("4. ç”Ÿæˆäº†è¯¦ç»†çš„è§„åˆ™éµå¾ªç»Ÿè®¡å’Œè¿åæ¨¡å¼åˆ†æ")
        print("5. ä¸ºæ¯ä¸ªé¡¹ç›®è®¡ç®—äº†å¼‚å¸¸è¯„åˆ†å¹¶è¿›è¡Œäº†é£é™©åˆ†ç±»")
        print("6. ç”Ÿæˆäº†ä¸“ä¸šçš„PDFå’ŒHTMLæ ¼å¼åˆ†ææŠ¥å‘Š")
        
        if 'generated_files' in locals() and generated_files:
            print("\nğŸ‰ å·²ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œè¯·æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶:")
            for report_type, file_path in generated_files.items():
                print(f"   â€¢ {report_type.upper()}æŠ¥å‘Š: {file_path}")
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()