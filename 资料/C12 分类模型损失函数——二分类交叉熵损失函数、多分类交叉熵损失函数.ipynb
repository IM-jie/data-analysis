{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d9a25b",
   "metadata": {},
   "source": [
    "# 二分类问题——二分类交叉熵损失函数（Binary Cross-Entropy Loss，BCE）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92728e",
   "metadata": {},
   "source": [
    "## 数学公式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec1de4",
   "metadata": {},
   "source": [
    "$$\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1-y_i)\\log(1-p_i) \\right]$$  \n",
    "其中，\n",
    "  - $y_i \\in \\{0, 1\\}$：样本的真实标签（0或1）。  \n",
    "  - $p_i \\in (0, 1)$：模型预测样本属于类别1的概率（通常由Sigmoid函数输出）。  \n",
    "  - $N$：样本数量。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30ba6a",
   "metadata": {},
   "source": [
    "## 核心思想"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf31b5d",
   "metadata": {},
   "source": [
    "二分类交叉熵损失函数对每个样本分别计算两个可能结果的加权对数概率：  \n",
    "  - 当$y_i=1$时，二分类交叉熵损失函数退化为$\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N}\\log(p_i)$，相当于仅计算$\\log(p_i)$，也即惩罚预测概率$p_i$偏离1的情况。  \n",
    "  - 当$y_i=0$时，二分类交叉熵损失函数退化为$\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N}\\log(1-p_i)$，相当于仅计算$\\log(1-p_i)$，也即惩罚预测概率$p_i$偏离0的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849fdd18",
   "metadata": {},
   "source": [
    "## 损失函数特性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f8737",
   "metadata": {},
   "source": [
    "1. **概率校准**: 二分类交叉熵损失函数直接优化预测概率与真实标签的匹配程度，而非仅关注分类边界，精度更高。\n",
    "2. **输出概率值**:  二分类交叉熵损失函数要求模型输出为概率值，而非直接输出类别标签。输出概率值能够更好反映模型预测的可信程度。\n",
    "3. **训练效率高**: \n",
    "   - 预测错误时（如$y_{i}=1$但$p_{i} \\to 0$），梯度较大，促使模型快速调整参数。  \n",
    "   - 预测正确且置信度高时（如$y_{i}=1$且$p_{i} \\to 1$），梯度趋近于0，参数更新放缓。  \n",
    "4. **数值稳定性**:\n",
    "    - 实际实现时，会通过数值优化（对log函数添加微小值$\\epsilon$）避免$\\log(0)$导致的数值溢出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d17b82c",
   "metadata": {},
   "source": [
    "## python实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bdc9f3",
   "metadata": {},
   "source": [
    "**np.clip**: 将数组中的值限定在指定的最小值 (a_min) 和最大值 (a_max) 之间\n",
    "  - `a`: 输入的数组\n",
    "  - `a_min`: 数组元素的下界，所有小于 a_min 的值都会被替换为 a_min\n",
    "  - `a_max`: 数组元素的上界，所有大于 a_max 的值都会被替换为 a_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbfc5742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18388253942874858"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred, epsilon=1e-15):\n",
    "    \"\"\"\n",
    "    手动实现二分类交叉熵损失函数（数值稳定版本）\n",
    "    \n",
    "    参数：\n",
    "    - y_true: 真实标签，形状 (N,)，取值 {0, 1}\n",
    "    - y_pred: 预测概率，形状 (N,)，取值 (0, 1)\n",
    "    - epsilon: 极小值，防止 log(0) 溢出\n",
    "    \n",
    "    返回：\n",
    "    - 平均损失值\n",
    "    \"\"\"\n",
    "    # 将预测值限制在 [epsilon, 1-epsilon] 范围内\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "y_true = np.array([1.0, 0.0, 1.0])\n",
    "y_pred = np.array([0.8, 0.2, 0.9])\n",
    "binary_cross_entropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8e249",
   "metadata": {},
   "source": [
    "# 多分类问题——多分类交叉熵损失函数（Categorical Cross-Entropy Loss，CCE）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a49f6",
   "metadata": {},
   "source": [
    "## 数学公式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de9f79",
   "metadata": {},
   "source": [
    "对于有$C$个类别的分类问题，给定样本的真实标签$y_{i,c}$和模型预测的类别概率$p_{i,c}$，多分类交叉熵损失定义如下：\n",
    "$$\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\log(p_{i,c})$$  \n",
    "其中：\n",
    "  - $y_{i,c} \\in \\{0, 1\\}$：样本$i$的真实标签是否为类别$c$，是为1，否为0。（将真实标签转换为 one-hot 编码形式，便于计算）\n",
    "  - $p_{i,c} \\in (0, 1)$：模型预测样本$i$属于类别$c$的概率。  \n",
    "  - $N$：样本数量，\n",
    "  - $C$：类别总数。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06158c",
   "metadata": {},
   "source": [
    "## 核心思想"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446512f",
   "metadata": {},
   "source": [
    "衡量模型预测的概率分布$p$与真实分布$y$之间的差异。\n",
    "- 如果$y_{i,c} = 1$（即该样本$i$属于类别$c$），则损失函数退化为$-\\log(p_{i,c})$，表示模型预测该类别的概率越大，损失越小。\n",
    "- 如果$y_{i,c} = 0$（即该样本$i$不属于类别$c$），则该类别不会影响损失函数计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e63a8",
   "metadata": {},
   "source": [
    "## 损失函数特性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942407a1",
   "metadata": {},
   "source": [
    "1. **概率校准**: 多分类交叉熵损失函数直接优化预测概率与真实标签的匹配程度，而非仅关注分类边界，精度更高。\n",
    "2. **输出概率值**:  多分类交叉熵损失函数要求模型输出为概率值，而非直接输出类别标签。输出概率值能够更好反映模型预测的可信程度。\n",
    "3. **训练效率高**: \n",
    "   - 预测错误时（如$y_{i,c}=1$但$p_{i,c} \\to 0$），梯度较大，促使模型快速调整参数。  \n",
    "   - 预测正确且置信度高时（如$y_{i,c}=1$且$p_{i,c} \\to 1$），梯度趋近于0，参数更新放缓。  \n",
    "4. **数值稳定性**:\n",
    "    - 实际实现时，会通过数值优化（对log函数添加微小值$\\epsilon$）避免$\\log(0)$导致的数值溢出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f96dd",
   "metadata": {},
   "source": [
    "## python实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa85ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手动实现多分类交叉熵损失: 0.3851\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def categorical_cross_entropy(y_true_labels, y_pred_probs, epsilon=1e-15):\n",
    "    \"\"\"\n",
    "    输入要求：\n",
    "    - y_true_labels: 真实类别索引（非one-hot），形状 (N,)\n",
    "    - y_pred_probs: 已归一化的预测概率（每个样本的概率和为1），形状 (N, C)\n",
    "    - epsilon: 极小值，防止log(0)溢出\n",
    "\n",
    "    返回：\n",
    "    - 多分类交叉熵损失\n",
    "    \"\"\"\n",
    "\n",
    "    # 提取真实类别对应的预测概率\n",
    "    N = y_pred_probs.shape[0] # 获取样本数量\n",
    "    true_probs = y_pred_probs[np.arange(N), y_true_labels] # 获取每个样本对应类别的预测概率值\n",
    "    \n",
    "    # 数值稳定处理：限制概率范围在 [epsilon, 1] 内\n",
    "    true_probs = np.clip(true_probs, epsilon, 1.0)\n",
    "    \n",
    "    # 计算交叉熵\n",
    "    loss = -np.mean(np.log(true_probs))\n",
    "    return loss\n",
    "\n",
    "# 示例数据：3个样本，3个类别\n",
    "y_true_labels = np.array([0, 2, 1])  # 真实类别索引\n",
    "y_pred_probs = np.array([\n",
    "    [0.9, 0.1, 0.0],    # 样本1：正确预测类别0\n",
    "    [0.2, 0.3, 0.5],    # 样本2：正确预测类别2\n",
    "    [0.1, 0.7, 0.2]     # 样本3：正确预测类别1\n",
    "])\n",
    "\n",
    "# 手动计算损失\n",
    "manual_loss = categorical_cross_entropy(y_true_labels, y_pred_probs)\n",
    "print(f\"手动实现多分类交叉熵损失: {manual_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ee511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a5b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12918931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
