#!/usr/bin/env python3
"""
ç®€åŒ–çš„KPIæ•°æ®æŒ–æ˜åŠŸèƒ½æµ‹è¯•
åªæµ‹è¯•æ ¸å¿ƒçš„å…³è”å…³ç³»æŒ–æ˜åŠŸèƒ½
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from utils.excel_reader import ExcelKPIReader, create_sample_excel
from analysis.kpi_association_miner import KPIAssociationMiner
from loguru import logger


def test_basic_association_mining():
    """æµ‹è¯•åŸºç¡€å…³è”å…³ç³»æŒ–æ˜"""
    print("=" * 60)
    print("æµ‹è¯•åŸºç¡€å…³è”å…³ç³»æŒ–æ˜")
    print("=" * 60)
    
    # 1. åˆ›å»ºç®€å•çš„ç¤ºä¾‹æ•°æ®
    print("1. åˆ›å»ºç®€å•ç¤ºä¾‹æ•°æ®...")
    
    # åˆ›å»ºæ›´ç®€å•çš„æ•°æ®
    data = {
        'éƒ¨é—¨åç§°': ['æŠ€æœ¯éƒ¨', 'äº§å“éƒ¨', 'è¿è¥éƒ¨'],
        'é¡¹ç›®æ•°é‡': [10, 8, 5],
        'åœ¨ç¼–äººæ•°': [50, 30, 20],
        'æ‰§è¡Œç”¨ä¾‹æ•°': [1000, 800, 500],
        'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°': [600, 400, 200],
        'ä»£ç è¦†ç›–ç‡': [0.85, 0.75, 0.65],
        'bugä¿®å¤ç‡': [0.90, 0.85, 0.80]
    }
    
    df = pd.DataFrame(data)
    simple_file = "simple_test_data.xlsx"
    df.to_excel(simple_file, index=False)
    print(f"   ç®€å•ç¤ºä¾‹æ–‡ä»¶å·²åˆ›å»º: {simple_file}")
    
    # 2. åˆå§‹åŒ–å…³è”å…³ç³»æŒ–æ˜å™¨
    print("\n2. åˆå§‹åŒ–å…³è”å…³ç³»æŒ–æ˜å™¨...")
    miner = KPIAssociationMiner()
    
    # 3. å®šä¹‰æŒ‡æ ‡åˆ—
    metric_columns = ['é¡¹ç›®æ•°é‡', 'åœ¨ç¼–äººæ•°', 'æ‰§è¡Œç”¨ä¾‹æ•°', 'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°', 'ä»£ç è¦†ç›–ç‡', 'bugä¿®å¤ç‡']
    
    print(f"   æŒ‡æ ‡åˆ—: {metric_columns}")
    
    # 4. è¿›è¡Œå…³è”å…³ç³»æŒ–æ˜ï¼ˆåªæµ‹è¯•ç›¸å…³æ€§åˆ†æï¼‰
    print("\n3. è¿›è¡Œç›¸å…³æ€§åˆ†æ...")
    try:
        correlation_results = miner._analyze_correlations(df, metric_columns)
        
        print("   ç›¸å…³æ€§åˆ†æç»“æœ:")
        strong_corrs = correlation_results.get('strong_correlations', [])
        print(f"   å¼ºç›¸å…³æ€§å…³ç³»æ•°é‡: {len(strong_corrs)}")
        
        if strong_corrs:
            print("   å¼ºç›¸å…³æ€§å…³ç³»:")
            for i, corr in enumerate(strong_corrs[:3], 1):
                print(f"     {i}. {corr['pair']} ({corr['method']}: {corr['correlation']:.3f})")
        else:
            print("   æœªå‘ç°å¼ºç›¸å…³æ€§å…³ç³»")
        
        # æ˜¾ç¤ºç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = correlation_results.get('matrix')
        if corr_matrix is not None:
            print(f"\n   ç›¸å…³æ€§çŸ©é˜µå½¢çŠ¶: {corr_matrix.shape}")
            print("   ç›¸å…³æ€§çŸ©é˜µ:")
            print(corr_matrix.round(3))
        
        return True
        
    except Exception as e:
        print(f"   ç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")
        return False


def test_mutual_information():
    """æµ‹è¯•äº’ä¿¡æ¯åˆ†æ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•äº’ä¿¡æ¯åˆ†æ")
    print("=" * 60)
    
    # ä½¿ç”¨ç®€å•æ•°æ®
    simple_file = "simple_test_data.xlsx"
    if not os.path.exists(simple_file):
        print("è¯·å…ˆè¿è¡ŒåŸºç¡€æµ‹è¯•åˆ›å»ºæ•°æ®æ–‡ä»¶")
        return False
    
    try:
        # è¯»å–æ•°æ®
        df = pd.read_excel(simple_file)
        metric_columns = ['é¡¹ç›®æ•°é‡', 'åœ¨ç¼–äººæ•°', 'æ‰§è¡Œç”¨ä¾‹æ•°', 'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°', 'ä»£ç è¦†ç›–ç‡', 'bugä¿®å¤ç‡']
        
        # åˆå§‹åŒ–æŒ–æ˜å™¨
        miner = KPIAssociationMiner()
        
        print("è¿›è¡Œäº’ä¿¡æ¯åˆ†æ...")
        mi_results = miner._analyze_mutual_information(df, metric_columns)
        
        print("äº’ä¿¡æ¯åˆ†æç»“æœ:")
        strong_mi = mi_results.get('strong_relationships', [])
        print(f"å¼ºäº’ä¿¡æ¯å…³ç³»æ•°é‡: {len(strong_mi)}")
        
        if strong_mi:
            print("å¼ºäº’ä¿¡æ¯å…³ç³»:")
            for i, mi in enumerate(strong_mi[:3], 1):
                print(f"  {i}. {mi['source']} -> {mi['target']} (MI: {mi['mi_score']:.3f})")
        else:
            print("æœªå‘ç°å¼ºäº’ä¿¡æ¯å…³ç³»")
        
        # æ˜¾ç¤ºäº’ä¿¡æ¯çŸ©é˜µ
        mi_matrix = mi_results.get('matrix')
        if mi_matrix is not None:
            print(f"\näº’ä¿¡æ¯çŸ©é˜µå½¢çŠ¶: {mi_matrix.shape}")
            print("äº’ä¿¡æ¯çŸ©é˜µ:")
            print(mi_matrix.round(3))
        
        return True
        
    except Exception as e:
        print(f"äº’ä¿¡æ¯åˆ†æå¤±è´¥: {e}")
        return False


def test_causality_analysis():
    """æµ‹è¯•å› æœå…³ç³»åˆ†æ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å› æœå…³ç³»åˆ†æ")
    print("=" * 60)
    
    # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
    print("1. åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®...")
    
    # åˆ›å»ºå¤šä¸ªæ—¶é—´ç‚¹çš„æ•°æ®
    time_data = []
    departments = ['æŠ€æœ¯éƒ¨', 'äº§å“éƒ¨', 'è¿è¥éƒ¨']
    
    for quarter in ['Q1', 'Q2', 'Q3']:
        for dept in departments:
            row = {
                'éƒ¨é—¨åç§°': dept,
                'quarter': quarter,
                'é¡¹ç›®æ•°é‡': np.random.randint(5, 15),
                'åœ¨ç¼–äººæ•°': np.random.randint(20, 60),
                'æ‰§è¡Œç”¨ä¾‹æ•°': np.random.randint(500, 1200),
                'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°': np.random.randint(200, 800),
                'ä»£ç è¦†ç›–ç‡': np.random.uniform(0.6, 0.9),
                'bugä¿®å¤ç‡': np.random.uniform(0.7, 0.95)
            }
            time_data.append(row)
    
    df_time = pd.DataFrame(time_data)
    time_file = "time_series_test_data.xlsx"
    df_time.to_excel(time_file, index=False)
    print(f"   æ—¶é—´åºåˆ—æ•°æ®å·²åˆ›å»º: {time_file}")
    
    try:
        # åˆå§‹åŒ–æŒ–æ˜å™¨
        miner = KPIAssociationMiner()
        metric_columns = ['é¡¹ç›®æ•°é‡', 'åœ¨ç¼–äººæ•°', 'æ‰§è¡Œç”¨ä¾‹æ•°', 'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°', 'ä»£ç è¦†ç›–ç‡', 'bugä¿®å¤ç‡']
        
        print("\n2. è¿›è¡Œå› æœå…³ç³»åˆ†æ...")
        causality_results = miner._analyze_causality(df_time, metric_columns)
        
        print("å› æœå…³ç³»åˆ†æç»“æœ:")
        lag_correlations = causality_results.get('lag_correlations', {})
        print(f"æ»åç›¸å…³æ€§å…³ç³»æ•°é‡: {len(lag_correlations)}")
        
        if lag_correlations:
            print("æ»åç›¸å…³æ€§å…³ç³»:")
            for pair, lag_corrs in list(lag_correlations.items())[:3]:
                if lag_corrs:
                    best_lag = max(lag_corrs, key=lambda x: abs(x['correlation']))
                    print(f"  {pair}: æœ€å¼ºæ»åç›¸å…³æ€§åœ¨æ»å{best_lag['lag']}æœŸ "
                          f"(ç›¸å…³æ€§: {best_lag['correlation']:.3f})")
        
        causal_chains = causality_results.get('causal_chains', [])
        print(f"å› æœå…³ç³»é“¾æ•°é‡: {len(causal_chains)}")
        
        if causal_chains:
            print("å› æœå…³ç³»é“¾:")
            for i, chain in enumerate(causal_chains[:3], 1):
                print(f"  {i}. {chain['source']} -> {chain['target']} "
                      f"(æ»å{chain['lag']}æœŸ, ç›¸å…³æ€§: {chain['correlation']:.3f})")
        
        return True
        
    except Exception as e:
        print(f"å› æœå…³ç³»åˆ†æå¤±è´¥: {e}")
        return False


def test_association_anomaly_detection():
    """æµ‹è¯•åŸºäºå…³è”å…³ç³»çš„å¼‚å¸¸æ£€æµ‹"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•åŸºäºå…³è”å…³ç³»çš„å¼‚å¸¸æ£€æµ‹")
    print("=" * 60)
    
    try:
        from analysis.kpi_association_miner import KPIAssociationAnomalyDetector
        
        # ä½¿ç”¨ç®€å•æ•°æ®
        simple_file = "simple_test_data.xlsx"
        if not os.path.exists(simple_file):
            print("è¯·å…ˆè¿è¡ŒåŸºç¡€æµ‹è¯•åˆ›å»ºæ•°æ®æ–‡ä»¶")
            return False
        
        # è¯»å–æ•°æ®
        df = pd.read_excel(simple_file)
        metric_columns = ['é¡¹ç›®æ•°é‡', 'åœ¨ç¼–äººæ•°', 'æ‰§è¡Œç”¨ä¾‹æ•°', 'è‡ªåŠ¨åŒ–æ‰§è¡Œç”¨ä¾‹æ•°', 'ä»£ç è¦†ç›–ç‡', 'bugä¿®å¤ç‡']
        
        # åˆå§‹åŒ–æŒ–æ˜å™¨å’Œæ£€æµ‹å™¨
        miner = KPIAssociationMiner()
        detector = KPIAssociationAnomalyDetector(miner)
        
        print("1. æ„å»ºå…³è”å…³ç³»åŸºçº¿...")
        baseline_results = detector.build_baseline(df, metric_columns)
        
        detection_rules = baseline_results.get('detection_rules', [])
        print(f"   æ„å»ºäº† {len(detection_rules)} ä¸ªæ£€æµ‹è§„åˆ™")
        
        if detection_rules:
            print("   æ£€æµ‹è§„åˆ™:")
            for i, rule in enumerate(detection_rules[:3], 1):
                if rule['type'] == 'correlation':
                    print(f"     {i}. ç›¸å…³æ€§è§„åˆ™: {rule['source']} <-> {rule['target']} "
                          f"(é¢„æœŸç›¸å…³æ€§: {rule['expected_correlation']:.3f})")
        
        # åˆ›å»ºå¼‚å¸¸æ•°æ®
        print("\n2. åˆ›å»ºå¼‚å¸¸æ•°æ®...")
        anomaly_data = df.copy()
        
        # æ¨¡æ‹Ÿå¼‚å¸¸ï¼šé¡¹ç›®æ•°é‡å¢åŠ ï¼Œä½†æ‰§è¡Œç”¨ä¾‹æ•°å‡å°‘
        if 'é¡¹ç›®æ•°é‡' in anomaly_data.columns and 'æ‰§è¡Œç”¨ä¾‹æ•°' in anomaly_data.columns:
            anomaly_data['é¡¹ç›®æ•°é‡'] = anomaly_data['é¡¹ç›®æ•°é‡'] * 1.5
            anomaly_data['æ‰§è¡Œç”¨ä¾‹æ•°'] = anomaly_data['æ‰§è¡Œç”¨ä¾‹æ•°'] * 0.7
            print("   æ¨¡æ‹Ÿå¼‚å¸¸: é¡¹ç›®æ•°é‡å¢åŠ 50%ï¼Œæ‰§è¡Œç”¨ä¾‹æ•°å‡å°‘30%")
        
        # æ£€æµ‹å¼‚å¸¸
        print("\n3. æ£€æµ‹å…³è”å…³ç³»å¼‚å¸¸...")
        anomalies = detector.detect_association_anomalies(anomaly_data, metric_columns)
        
        # åˆ†æå¼‚å¸¸ç»“æœ
        print("\n4. å¼‚å¸¸æ£€æµ‹ç»“æœ:")
        summary = anomalies.get('summary', {})
        print(f"   æ€»å¼‚å¸¸æ•°é‡: {summary.get('total_anomalies', 0)}")
        print(f"   ç›¸å…³æ€§å¼‚å¸¸: {summary.get('correlation_anomalies', 0)}")
        print(f"   å› æœå…³ç³»å¼‚å¸¸: {summary.get('causality_anomalies', 0)}")
        print(f"   é«˜ä¸¥é‡æ€§å¼‚å¸¸: {summary.get('high_severity', 0)}")
        
        # ç”Ÿæˆæ´å¯Ÿ
        print("\n5. å¼‚å¸¸æ´å¯Ÿ:")
        insights = detector.generate_anomaly_insights(anomalies)
        for i, insight in enumerate(insights[:3], 1):
            print(f"   {i}. {insight}")
        
        return True
        
    except Exception as e:
        print(f"å¼‚å¸¸æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ç®€åŒ–çš„KPIæ•°æ®æŒ–æ˜åŠŸèƒ½æµ‹è¯•")
    print("æœ¬æµ‹è¯•å°†éªŒè¯æ ¸å¿ƒçš„æ•°æ®æŒ–æ˜åŠŸèƒ½")
    
    results = []
    
    try:
        # è¿è¡Œå„ä¸ªæµ‹è¯•
        results.append(("åŸºç¡€å…³è”å…³ç³»æŒ–æ˜", test_basic_association_mining()))
        results.append(("äº’ä¿¡æ¯åˆ†æ", test_mutual_information()))
        results.append(("å› æœå…³ç³»åˆ†æ", test_causality_analysis()))
        results.append(("å¼‚å¸¸æ£€æµ‹", test_association_anomaly_detection()))
        
        # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        print("\n" + "=" * 60)
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 60)
        
        passed = 0
        total = len(results)
        
        for test_name, success in results:
            status = "âœ“ é€šè¿‡" if success else "âœ— å¤±è´¥"
            print(f"{test_name}: {status}")
            if success:
                passed += 1
        
        print(f"\næ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
        
        if passed == total:
            print("\nğŸ‰ æ‰€æœ‰æ•°æ®æŒ–æ˜åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
            print("\næ•°æ®æŒ–æ˜åŠŸèƒ½ç‰¹ç‚¹:")
            print("1. âœ“ ç›¸å…³æ€§åˆ†æ - å‘ç°æŒ‡æ ‡é—´çš„çº¿æ€§å…³ç³»")
            print("2. âœ“ äº’ä¿¡æ¯åˆ†æ - å‘ç°æŒ‡æ ‡é—´çš„éçº¿æ€§å…³ç³»")
            print("3. âœ“ å› æœå…³ç³»åˆ†æ - å‘ç°æŒ‡æ ‡é—´çš„æ—¶åºå…³ç³»")
            print("4. âœ“ å¼‚å¸¸æ£€æµ‹ - åŸºäºå…³è”å…³ç³»å˜åŒ–æ£€æµ‹å¼‚å¸¸")
            print("5. âœ“ ä¸šåŠ¡æ´å¯Ÿ - ç”Ÿæˆå¯ç†è§£çš„ä¸šåŠ¡å»ºè®®")
            
            print("\nä½¿ç”¨å»ºè®®:")
            print("- ä½¿ç”¨ --associations å‚æ•°è¿›è¡Œä¸“é—¨çš„å…³è”å…³ç³»åˆ†æ")
            print("- ç»“åˆä¸šåŠ¡èƒŒæ™¯ç†è§£å…³è”å…³ç³»ç»“æœ")
            print("- å…³æ³¨é«˜ä¸¥é‡æ€§çš„å…³è”å…³ç³»å¼‚å¸¸")
            print("- å®šæœŸæ›´æ–°å…³è”å…³ç³»åŸºçº¿")
        else:
            print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        test_files = ["simple_test_data.xlsx", "time_series_test_data.xlsx"]
        for file in test_files:
            if os.path.exists(file):
                os.remove(file)
                print(f"å·²æ¸…ç†æµ‹è¯•æ–‡ä»¶: {file}")
        
    except Exception as e:
        logger.error(f"æ•°æ®æŒ–æ˜æµ‹è¯•å¤±è´¥: {e}")
        print(f"\né”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…")


if __name__ == "__main__":
    main()
