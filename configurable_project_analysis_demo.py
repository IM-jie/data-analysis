#!/usr/bin/env python3
"""
å¯é…ç½®é¡¹ç›®æ•°æ®Aprioriåˆ†æç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¯é…ç½®åˆ†æå™¨è¿›è¡Œé¡¹ç›®æ•°æ®å…³è”è§„åˆ™æŒ–æ˜å’Œæ ‡ç­¾åˆ†ç±»
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / 'src'))

try:
    from analysis.configurable_project_analyzer import ConfigurableProjectAnalyzer
    ANALYZER_AVAILABLE = True
    print("âœ… å¯é…ç½®é¡¹ç›®åˆ†æå™¨åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âŒ åˆ†æå™¨å¯¼å…¥å¤±è´¥: {e}")
    ANALYZER_AVAILABLE = False


def create_sample_english_data():
    """åˆ›å»ºè‹±æ–‡å­—æ®µçš„ç¤ºä¾‹é¡¹ç›®æ•°æ®"""
    print("åˆ›å»ºç¤ºä¾‹é¡¹ç›®æ•°æ®ï¼ˆè‹±æ–‡å­—æ®µï¼‰...")
    
    np.random.seed(42)
    n_projects = 150
    
    # è‹±æ–‡å­—æ®µæ•°æ®
    project_types = ['Web_App', 'Mobile_App', 'API_Service', 'Desktop_App', 'Data_Platform']
    project_levels = ['P0', 'P1', 'P2', 'P3']
    product_lines = ['E_Commerce', 'Financial_Service', 'Social_Media', 'Enterprise_Service']
    product_types = ['Frontend', 'Backend', 'Full_Stack']
    organizations = ['QA_Team_A', 'QA_Team_B', 'QA_Team_C', 'Outsource_Team_D']
    test_owners = [f'Tester_{i:02d}' for i in range(1, 16)]
    
    data = []
    
    for i in range(n_projects):
        project_type = np.random.choice(project_types)
        project_level = np.random.choice(project_levels)
        product_line = np.random.choice(product_lines)
        product_type = np.random.choice(product_types)
        organization = np.random.choice(organizations)
        test_owner = np.random.choice(test_owners)
        
        # åˆ›å»ºä¸€äº›å…³è”è§„å¾‹
        
        # è§„å¾‹1: Web_App + P0 -> QA_Team_A (80%æ¦‚ç‡)
        if project_type == 'Web_App' and project_level == 'P0':
            if np.random.random() < 0.2:
                organization = np.random.choice(['QA_Team_B', 'QA_Team_C'])
            else:
                organization = 'QA_Team_A'
        
        # è§„å¾‹2: Financial_Service -> P0 (75%æ¦‚ç‡)
        if product_line == 'Financial_Service':
            if np.random.random() < 0.25:
                project_level = np.random.choice(['P1', 'P2'])
            else:
                project_level = 'P0'
        
        # è§„å¾‹3: Mobile_App -> Frontend (70%æ¦‚ç‡)
        if project_type == 'Mobile_App':
            if np.random.random() < 0.3:
                product_type = np.random.choice(['Backend', 'Full_Stack'])
            else:
                product_type = 'Frontend'
        
        # åŸºç¡€æŒ‡æ ‡è®¡ç®—
        level_multiplier = {'P0': 2.5, 'P1': 2.0, 'P2': 1.5, 'P3': 1.0}[project_level]
        type_multiplier = {
            'Web_App': 1.2, 'Mobile_App': 1.0, 'API_Service': 0.8, 
            'Desktop_App': 1.1, 'Data_Platform': 1.5
        }[project_type]
        
        base_cases = int(np.random.normal(100 * level_multiplier * type_multiplier, 30))
        executed_cases = max(20, base_cases)
        
        automation_rate = np.random.uniform(0.3, 0.8)
        if project_type in ['API_Service', 'Web_App']:
            automation_rate = np.random.uniform(0.5, 0.9)  # æ›´é«˜çš„è‡ªåŠ¨åŒ–ç‡
        
        automated_cases = int(executed_cases * automation_rate)
        related_bugs = max(1, int(executed_cases * np.random.uniform(0.02, 0.08)))
        effort_hours = max(20, int(executed_cases * np.random.uniform(0.3, 0.7)))
        
        data.append({
            'project_name': f'Project_{product_line}_{project_type}_{i+1:03d}',
            'project_id': f'PRJ-{i+1:04d}',
            'project_type': project_type,
            'project_level': project_level,
            'product_line': product_line,
            'product_type': product_type,
            'test_owner': test_owner,
            'test_owner_org': organization,
            'executed_cases': executed_cases,
            'automated_cases': automated_cases,
            'related_bugs': related_bugs,
            'effort_hours': effort_hours
        })
    
    df = pd.DataFrame(data)
    
    # ä¿å­˜æ•°æ®
    output_file = 'sample_project_data_english.xlsx'
    df.to_excel(output_file, index=False)
    print(f"ç¤ºä¾‹æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    return df


def demonstrate_configurable_analysis():
    """æ¼”ç¤ºå¯é…ç½®åˆ†æåŠŸèƒ½"""
    print("\n" + "=" * 80)
    print("å¯é…ç½®é¡¹ç›®æ•°æ®Aprioriåˆ†ææ¼”ç¤º")
    print("=" * 80)
    
    if not ANALYZER_AVAILABLE:
        print("åˆ†æå™¨ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–")
        return
    
    # 1. åˆ›å»ºé…ç½®æ¨¡æ¿
    print("\n1. åˆ›å»ºé…ç½®æ¨¡æ¿...")
    config_dir = Path('config')
    config_dir.mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–åˆ†æå™¨ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    analyzer = ConfigurableProjectAnalyzer()
    
    # åˆ›å»ºé…ç½®æ¨¡æ¿
    config_file = analyzer.create_config_template()
    print(f"   é…ç½®æ¨¡æ¿å·²åˆ›å»º: {config_file}")
    
    # 2. æ˜¾ç¤ºå­—æ®µé…ç½®ä¿¡æ¯
    print("\n2. å­—æ®µé…ç½®ä¿¡æ¯:")
    field_info = analyzer.get_field_info()
    print(f"   ç»´åº¦å­—æ®µï¼ˆä¸­æ–‡ï¼‰: {field_info['dimension_fields_chinese']}")
    print(f"   æŒ‡æ ‡å­—æ®µï¼ˆä¸­æ–‡ï¼‰: {field_info['metric_fields_chinese']}")
    print(f"   å­—æ®µæ˜ å°„æ•°é‡: {len(field_info['field_mapping'])}")
    
    # 3. åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\n3. åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    project_data = create_sample_english_data()
    print(f"   æ•°æ®å½¢çŠ¶: {project_data.shape}")
    print(f"   æ•°æ®åˆ—: {list(project_data.columns)}")
    
    # 4. éªŒè¯æ•°æ®
    print("\n4. éªŒè¯æ•°æ®æ ¼å¼...")
    is_valid, errors = analyzer.validate_data(project_data)
    if is_valid:
        print("   âœ… æ•°æ®éªŒè¯é€šè¿‡")
    else:
        print(f"   âŒ æ•°æ®éªŒè¯å¤±è´¥: {errors}")
        return
    
    # 5. æ‰§è¡Œåˆ†æ
    print("\n5. æ‰§è¡Œå¯é…ç½®Aprioriåˆ†æ...")
    
    start_time = datetime.now()
    analysis_results = analyzer.analyze_project_data(project_data)
    end_time = datetime.now()
    
    analysis_duration = (end_time - start_time).total_seconds()
    print(f"   åˆ†æè€—æ—¶: {analysis_duration:.2f}ç§’")
    
    # 6. æ˜¾ç¤ºåˆ†ææ‘˜è¦
    print("\n6. åˆ†æç»“æœæ‘˜è¦:")
    summary = analysis_results['summary']
    
    if 'association_rules' in summary:
        rule_summary = summary['association_rules']
        print(f"   å…³è”è§„åˆ™æ€»æ•°: {rule_summary['total_rules']}")
        print(f"   é«˜ç½®ä¿¡åº¦è§„åˆ™: {rule_summary['high_confidence_rules']}")
        print(f"   å¼ºå…³è”å…³ç³»: {rule_summary['strong_associations']}")
    
    if 'correlations' in summary:
        corr_summary = summary['correlations']
        print(f"   å¼ºç›¸å…³æ€§æ•°é‡: {corr_summary['strong_correlations']}")
        if corr_summary['correlation_details']:
            print("   å‰3ä¸ªå¼ºç›¸å…³æ€§:")
            for i, corr in enumerate(corr_summary['correlation_details'][:3], 1):
                print(f"     {i}. {corr['field1']} â†” {corr['field2']}: {corr['correlation']:.3f}")
    
    if 'labeling' in summary:
        label_summary = summary['labeling']
        print(f"   æ•°æ®æ ‡ç­¾åˆ†ç±»:")
        for category, count in label_summary['category_distribution'].items():
            print(f"     {category}: {count}é¡¹")
        print(f"   è¿åè§„åˆ™é¡¹ç›®: {label_summary['violation_count']}é¡¹ ({label_summary['violation_rate']:.1%})")
    
    # 7. æ˜¾ç¤ºå…³è”è§„åˆ™è¯¦æƒ…
    print("\n7. å…³è”è§„åˆ™è¯¦æƒ…ï¼ˆå‰5ä¸ªï¼‰:")
    mining_results = analysis_results['mining_results']
    association_rules = mining_results.get('categorical_associations', {}).get('association_rules', [])
    
    for i, rule in enumerate(association_rules[:5], 1):
        antecedents = ' & '.join(rule.get('antecedents', []))
        consequents = ' & '.join(rule.get('consequents', []))
        confidence = rule.get('confidence', 0)
        support = rule.get('support', 0)
        lift = rule.get('lift', 1)
        
        print(f"   è§„åˆ™{i}: {antecedents} => {consequents}")
        print(f"          ç½®ä¿¡åº¦: {confidence:.3f}, æ”¯æŒåº¦: {support:.3f}, æå‡åº¦: {lift:.3f}")
    
    # 8. æ˜¾ç¤ºè¿åè§„åˆ™çš„é¡¹ç›®
    print("\n8. è¿åè§„åˆ™çš„é¡¹ç›®ç¤ºä¾‹ï¼ˆå‰3ä¸ªï¼‰:")
    labeled_data = analysis_results['labeled_data']
    if labeled_data is not None:
        violation_data = labeled_data[labeled_data['rule_violations'] != '']
        
        if len(violation_data) > 0:
            sample_violations = violation_data.head(3)
            for idx, row in sample_violations.iterrows():
                print(f"   é¡¹ç›®: {row.get('é¡¹ç›®åç§°', 'N/A')}")
                print(f"   ç‰¹å¾: {row.get('é¡¹ç›®ç±»å‹', 'N/A')}, {row.get('é¡¹ç›®çº§åˆ«', 'N/A')}")
                print(f"   è¿åè§„åˆ™: {row.get('rule_violations', 'N/A')}")
                print(f"   å¼‚å¸¸è¯„åˆ†: {row.get('anomaly_score', 0):.3f}")
                print()
        else:
            print("   æœªå‘ç°è¿åè§„åˆ™çš„é¡¹ç›®")
    
    # 9. ç”ŸæˆæŠ¥å‘Š
    print("\n9. ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    try:
        generated_files = analyzer.generate_reports(analysis_results)
        
        if generated_files:
            print("   âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ:")
            for report_type, file_path in generated_files.items():
                print(f"     {report_type.upper()}æŠ¥å‘Š: {file_path}")
        else:
            print("   âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥æˆ–è·³è¿‡")
    except Exception as e:
        print(f"   âŒ æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {e}")
    
    return analysis_results


def demonstrate_custom_configuration():
    """æ¼”ç¤ºè‡ªå®šä¹‰é…ç½®åŠŸèƒ½"""
    print("\n" + "=" * 80)
    print("è‡ªå®šä¹‰é…ç½®æ¼”ç¤º")
    print("=" * 80)
    
    # è‡ªå®šä¹‰é…ç½®
    custom_config = {
        "field_mapping": {
            "proj_name": "é¡¹ç›®åç§°",
            "proj_id": "é¡¹ç›®ç¼–å·",
            "proj_type": "é¡¹ç›®ç±»å‹",
            "proj_level": "é¡¹ç›®çº§åˆ«",
            "prod_line": "äº§å“çº¿",
            "test_cases": "æµ‹è¯•ç”¨ä¾‹æ•°",
            "auto_cases": "è‡ªåŠ¨åŒ–ç”¨ä¾‹æ•°",
            "bug_count": "ç¼ºé™·æ•°é‡",
            "work_hours": "å·¥ä½œå°æ—¶"
        },
        "dimension_fields": [
            "proj_type", "proj_level", "prod_line"
        ],
        "metric_fields": [
            "test_cases", "auto_cases", "bug_count", "work_hours"
        ],
        "analysis_parameters": {
            "min_support": 0.03,
            "min_confidence": 0.7,
            "min_lift": 1.5,
            "correlation_threshold": 0.7
        },
        "reporting": {
            "output_format": ["html"],  # åªç”ŸæˆHTMLæŠ¥å‘Š
            "output_directory": "custom_reports",
            "include_charts": True,
            "include_tables": True
        }
    }
    
    print("1. ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆå§‹åŒ–åˆ†æå™¨...")
    try:
        custom_analyzer = ConfigurableProjectAnalyzer(config_dict=custom_config)
        print("   âœ… è‡ªå®šä¹‰é…ç½®åŠ è½½æˆåŠŸ")
        
        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        field_info = custom_analyzer.get_field_info()
        print(f"   è‡ªå®šä¹‰ç»´åº¦å­—æ®µ: {field_info['dimension_fields']}")
        print(f"   è‡ªå®šä¹‰æŒ‡æ ‡å­—æ®µ: {field_info['metric_fields']}")
        
        # å¯¼å‡ºé…ç½®
        config_export_file = "config/custom_config_export.yaml"
        custom_analyzer.export_configuration(config_export_file)
        print(f"   é…ç½®å·²å¯¼å‡ºåˆ°: {config_export_file}")
        
    except Exception as e:
        print(f"   âŒ è‡ªå®šä¹‰é…ç½®åŠ è½½å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("å¯é…ç½®é¡¹ç›®æ•°æ®Aprioriåˆ†ææ¼”ç¤º")
    print("=" * 60)
    
    try:
        # åŸºæœ¬æ¼”ç¤º
        analysis_results = demonstrate_configurable_analysis()
        
        # è‡ªå®šä¹‰é…ç½®æ¼”ç¤º
        demonstrate_custom_configuration()
        
        print("\n" + "=" * 60)
        print("æ¼”ç¤ºå®Œæˆï¼")
        print("\nåŠŸèƒ½ç‰¹æ€§:")
        print("âœ… æ”¯æŒè‡ªå®šä¹‰ç»´åº¦å­—æ®µå’ŒæŒ‡æ ‡å­—æ®µé…ç½®")
        print("âœ… æ”¯æŒè‹±æ–‡å­—æ®µååˆ°ä¸­æ–‡æ˜¾ç¤ºåçš„æ˜ å°„")
        print("âœ… æ”¯æŒå¯é…ç½®çš„Aprioriç®—æ³•å‚æ•°")
        print("âœ… æ”¯æŒæ•°æ®éªŒè¯å’Œæ ¼å¼æ£€æŸ¥")
        print("âœ… æ”¯æŒå…³è”è§„åˆ™æŒ–æ˜å’Œæ•°æ®æ ‡ç­¾åˆ†ç±»")
        print("âœ… æ”¯æŒå¤šæ ¼å¼æŠ¥å‘Šç”Ÿæˆï¼ˆPDF/HTMLï¼‰")
        print("âœ… æ”¯æŒé…ç½®æ¨¡æ¿ç”Ÿæˆå’Œå¯¼å‡º")
        
        if 'analysis_results' in locals():
            print("\nåˆ†æäº®ç‚¹:")
            summary = analysis_results.get('summary', {})
            if 'association_rules' in summary:
                print(f"ğŸ” å‘ç°äº† {summary['association_rules']['total_rules']} ä¸ªå…³è”è§„åˆ™")
            if 'labeling' in summary:
                print(f"ğŸ·ï¸ æ ‡ç­¾åˆ†ç±»è¿åç‡: {summary['labeling']['violation_rate']:.1%}")
            print("ğŸ“Š ç”Ÿæˆäº†å®Œæ•´çš„å¯è§†åŒ–åˆ†ææŠ¥å‘Š")
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()