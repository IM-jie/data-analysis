{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22747fd4",
   "metadata": {},
   "source": [
    "# 参数与超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f42ef",
   "metadata": {},
   "source": [
    "**超参数**是指模型中无法通过学习得到，需要人工事先指定的模型参数。\n",
    "\n",
    "在机器学习中，**调参**也即超参数调整是提升模型效果的关键步骤。\n",
    "\n",
    "机器学习中的调参有\n",
    "  - **手动调参**\n",
    "  - **网格搜索（GridSearchCV）**\n",
    "  - **随机搜索（RandomizedSearchCV）**\n",
    "  - **贝叶斯搜索（BayesSearchCV）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62341c25",
   "metadata": {},
   "source": [
    "# 手动调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0f25a",
   "metadata": {},
   "source": [
    "**手动调参**是指通过人工调整模型的超参数，观察模型性能的变化，逐步找到最优参数组合的过程。\n",
    "\n",
    "相比于自动调参（网格搜索GridSearchCV、随机搜索RandomizedSearchCV、贝叶斯搜索BayesSearchCV），手动调参耗费资源少、更加直观便捷。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ab812",
   "metadata": {},
   "source": [
    "## 手动调参步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8aca3",
   "metadata": {},
   "source": [
    "1. 确定关键参数: 根据超参数作用确定要调整的超参数对象\n",
    "2. 确定评估指标\n",
    "    - 分类任务：准确率（accuracy）、F1分数（f1_score）、AUC-ROC（roc_auc_score）。\n",
    "    - 回归任务：均方误差（MSE）、R²分数（r2_score）。\n",
    "3. 训练模型并观察性能\n",
    "    - 每次调整1~2个参数，记录训练集和验证集的得分。\n",
    "    - 使用交叉验证（如cross_val_score）避免过拟合。\n",
    "4. 手动调整参数\n",
    "    - 如果模型欠拟合（训练集和验证集得分都低）：\n",
    "        - 增加模型复杂度（如增大 max_depth、增加 n_estimators）。\n",
    "        - 减少正则化（如减小 min_samples_split）。\n",
    "    - 如果模型过拟合（训练集得分高，验证集得分低）：\n",
    "        - 降低模型复杂度（如减小 max_depth）。\n",
    "        - 增加正则化（如增大 min_samples_split）\n",
    "5. 重复以上步骤直至效果满意"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd57c02",
   "metadata": {},
   "source": [
    "## 手动调参技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e42dfa",
   "metadata": {},
   "source": [
    "- 先调重要参数（如随机森林的 max_depth、n_estimators）。\n",
    "- 每次只调1个参数，避免混淆影响。\n",
    "- 记录每次实验的结果，便于回溯分析。\n",
    "- 结合学习曲线判断欠拟合/过拟合。\n",
    "- 最终用测试集验证，避免数据泄露。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fdf322",
   "metadata": {},
   "source": [
    "# 网格搜索GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb675dab",
   "metadata": {},
   "source": [
    "**GridSearchCV**通过**网格搜索（Grid Search）结合交叉验证（Cross Validation）**的方式，系统地遍历多个参数组合，从中找到使模型性能最优的那一组超参数。\n",
    "\n",
    "具体来说，网格搜索将每个超参数的可能取值组合成一个网格，然后穷举搜索所有可能的组合，对每个组合进行交叉验证，并评估模型在验证集上的性能。最终选择在验证集上性能最佳的超参数组合作为最终的模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7eb8b",
   "metadata": {},
   "source": [
    "## 网格搜索GridSearchCV优缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c912288",
   "metadata": {},
   "source": [
    "- 优点\n",
    "    - 简单易用\n",
    "    - 在提供的网格内保证能够找到“全局最优”的一组超参数\n",
    "    - 结合交叉验证，鲁棒性强\n",
    "- 缺点\n",
    "    - 参数组合多或数据集大时耗费计算开销大\n",
    "    - 只适用于离散搜索空间（无法自动缩放或自适应调整）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004bb31",
   "metadata": {},
   "source": [
    "## GridSearchCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aaba0f",
   "metadata": {},
   "source": [
    "- `estimator`: 要被调参的模型对象\n",
    "- `param_grid`: 一个字典或字典列表，定义参数搜索空间\n",
    "- `scoring`: 模型评估标准\n",
    "- `n_jobs`: 并行计算使用的 CPU 核心数\n",
    "    - n_jobs=1: 单线程\n",
    "    - n_jobs=-1: 使用全部 CPU 核心（推荐）\n",
    "- `cv`: 设置交叉验证方式\n",
    "    - None：默认 5 折交叉验证\n",
    "    - 整数：表示 K 折。如 cv=10表示十折\n",
    "    - 对象：KFold、StratifiedKFold（参考C04课程讲解）\n",
    "- `verbose`: 控制日志输出信息量\n",
    "    - 0: 不输出\n",
    "    - 1: 输出基本信息\n",
    "    - 2: 更详细（推荐用于调试）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e37b3",
   "metadata": {},
   "source": [
    "## 返回结果\n",
    "- `.best_params_`：最佳参数组合\n",
    "- `.best_score_`：最佳得分（交叉验证）\n",
    "- `.best_estimator_`：最优模型对象（如果 refit=True）\n",
    "- `.cv_results_`：包含所有搜索结果的详细信息字典，可转换为 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb233b",
   "metadata": {},
   "source": [
    "## Iris鸢尾花数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e064ba3",
   "metadata": {},
   "source": [
    "Iris鸢尾花数据集是一个经典的机器学习数据集，包含了三种鸢尾花（Setosa, Versicolor, Virginica）的不同特征，每个花种有 50 个样本，总共有 150 个样本\n",
    "- sepal_length：花萼长度\n",
    "- sepal_width：花萼宽度\n",
    "- petal_length：花瓣长度\n",
    "- petal_width：花瓣宽度\n",
    "- species：花种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695297b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "iris = load_iris() # 加载鸢尾花数据集\n",
    "X = iris.data # 自变量\n",
    "y = iris.target  # 因变量\n",
    "feature_names = iris.feature_names # 特征名称\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de8b82",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcf01ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3, 'max_features': 0.5, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best cross-val score: 0.9500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from sklearn.ensemble import RandomForestClassifier  # 随机森林分类器\n",
    "from sklearn.datasets import load_iris  # 鸢尾花数据集\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # 数据分割和网格搜索\n",
    "from sklearn.metrics import classification_report  # 分类评估报告\n",
    "\n",
    "# 1. 加载数据\n",
    "# ------------------------------------------------\n",
    "# 使用sklearn自带的鸢尾花数据集（150个样本，4个特征，3个类别）\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target  # X是特征矩阵，y是目标标签\n",
    "\n",
    "# 2. 划分训练集和验证集\n",
    "# ------------------------------------------------\n",
    "# 随机拆分数据，验证集占20%，random_state保证每次运行结果一致\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. 定义参数网格\n",
    "# ------------------------------------------------\n",
    "# 指定需要搜索的超参数组合：\n",
    "# - n_estimators: 树的数量 [50, 100, 200]\n",
    "# - max_depth: 树的最大深度 [3, 5, 7]\n",
    "# - min_samples_split: 节点分裂所需最小样本数 [2, 4]\n",
    "# - 'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "# 共 3 * 3 * 2 * 9 = 162 种组合\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "}\n",
    "\n",
    "# 4. 初始化GridSearchCV\n",
    "# ------------------------------------------------\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),  # 基础模型\n",
    "    param_grid=param_grid,  # 参数网格\n",
    "    cv=5,                  # 5折交叉验证\n",
    "    scoring='accuracy',    # 评估指标（准确率）\n",
    "    n_jobs=-1              # 使用所有CPU核心并行计算\n",
    ")\n",
    "\n",
    "# 5. 执行网格搜索\n",
    "# ------------------------------------------------\n",
    "# 对18种参数组合分别进行5折交叉验证，共162 * 5=810次训练\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 6. 输出最优结果\n",
    "# ------------------------------------------------\n",
    "print(\"Best parameters:\", grid_search.best_params_)  # 最佳参数组合\n",
    "print(\"Best cross-val score: {:.4f}\".format(grid_search.best_score_))  # 最佳交叉验证准确率\n",
    "\n",
    "# 7. 在测试集上评估\n",
    "# ------------------------------------------------\n",
    "# 用最优参数的模型预测验证集\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# 打印分类报告（包含精确率、召回率、F1值等）\n",
    "# - precision: 精确率（预测为正例中实际为正的比例）\n",
    "# - recall: 召回率（实际为正例中被正确预测的比例）\n",
    "# - f1-score: 精确率和召回率的调和平均\n",
    "# - support: 各类别样本数\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbed08f",
   "metadata": {},
   "source": [
    "# 随机搜索RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a46c77",
   "metadata": {},
   "source": [
    "**RandomizedSearchCV** 是 scikit-learn 提供的一种超参数优化方法，用于在给定的参数空间中随机采样并评估模型性能\n",
    "\n",
    "- **核心原理**\n",
    "    - **随机采样**：从参数分布（如均匀分布、离散列表）中抽取固定次数的参数组合，而非穷举所有可能（网格搜索）。\n",
    "    - **交叉验证**：对每组参数使用交叉验证（如 5 折）评估模型性能。\n",
    "    - **返回最佳参数**：选择交叉验证得分最高的参数组合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e432257",
   "metadata": {},
   "source": [
    "## 随机搜索RandomizedSearchCV优缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a4380",
   "metadata": {},
   "source": [
    "- 优点\n",
    "    - 计算效率高：相比网格搜索（GridSearchCV），随机搜索不穷举所有参数组合，而是通过随机采样（n_iter 次）减少计算量，特别适合高维参数空间或训练耗时的模型（如深度学习、GBDT）。\n",
    "    - 避免局部最优陷阱：尤其在参数间存在非线性交互时（如神经网络的层数与学习率）， 随机搜索RandomizedSearchCV的随机性可帮助跳出局部最优解。\n",
    "- 缺点：\n",
    "    - 可能错过全局最优：依赖随机采样，若 n_iter 过小或参数分布设计不合理，可能漏掉关键参数组合（例如网格搜索能找到但随机搜索未抽样的点）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35e133",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b7b1a",
   "metadata": {},
   "source": [
    "- `estimator`: 要被调参的模型对象\n",
    "- `param_distributions`: 参数空间字典，定义参数搜索空间\n",
    "- `n_iter`: 随机采样的参数组合数量（越大越可能找到最优解，但计算成本越高）\n",
    "- `scoring`: 模型评估标准\n",
    "- `n_jobs`: 并行计算使用的 CPU 核心数\n",
    "    - n_jobs=1: 单线程\n",
    "    - n_jobs=-1: 使用全部 CPU 核心（推荐）\n",
    "- `cv`: 设置交叉验证方式\n",
    "    - None：默认 5 折交叉验证\n",
    "    - 整数：表示 K 折。如 cv=10表示十折\n",
    "    - 对象：KFold、StratifiedKFold（参考C04课程讲解）\n",
    "- `verbose`: 控制日志输出信息量\n",
    "    - 0: 不输出\n",
    "    - 1: 输出基本信息\n",
    "    - 2: 更详细（推荐用于调试）\n",
    "- `random_state`: 随机数种子（保证结果可复现）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c57b63",
   "metadata": {},
   "source": [
    "## 返回结果\n",
    "- `.best_params_`：最佳参数组合\n",
    "- `.best_score_`：最佳得分（交叉验证）\n",
    "- `.best_estimator_`：最优模型对象（如果 refit=True）\n",
    "- `.cv_results_`：包含所有搜索结果的详细信息字典，可转换为 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc19a84",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7fc4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 200, 'min_samples_split': 2, 'max_features': 0.9, 'max_depth': 7}\n",
      "Best cross-val score: 0.9500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from sklearn.ensemble import RandomForestClassifier  # 随机森林分类器\n",
    "from sklearn.datasets import load_iris  # 鸢尾花数据集\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV  # 数据分割和随机搜索\n",
    "from sklearn.metrics import classification_report  # 分类评估报告\n",
    "from scipy.stats import randint, uniform  # 用于定义参数的概率分布\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 1. 加载数据\n",
    "# ------------------------------------------------\n",
    "# 使用sklearn自带的鸢尾花数据集（150个样本，4个特征，3个类别）\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target  # X是特征矩阵，y是目标标签\n",
    "\n",
    "# 2. 划分训练集和验证集\n",
    "# ------------------------------------------------\n",
    "# 随机拆分数据，验证集占20%，random_state保证每次运行结果一致\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. 定义参数分布\n",
    "# ------------------------------------------------\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "}\n",
    "\n",
    "# 4. 初始化RandomizedSearchCV\n",
    "# ------------------------------------------------\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),  # 基础模型\n",
    "    param_distributions=param_dist,  # 参数分布\n",
    "    n_iter=20,                       # 随机采样20组参数组合\n",
    "    cv=5,                            # 5折交叉验证\n",
    "    scoring='accuracy',              # 评估指标（准确率）\n",
    "    random_state=42,                 # 保证结果可复现\n",
    "    n_jobs=-1                        # 使用所有CPU核心并行计算\n",
    ")\n",
    "\n",
    "# 5. 执行随机搜索\n",
    "# ------------------------------------------------\n",
    "# 对随机采样的20种参数组合分别进行5折交叉验证，共20 * 5=100次训练\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 6. 输出最优结果\n",
    "# ------------------------------------------------\n",
    "print(\"Best parameters:\", random_search.best_params_)  # 最佳参数组合\n",
    "print(\"Best cross-val score: {:.4f}\".format(random_search.best_score_))  # 最佳交叉验证准确率\n",
    "\n",
    "# 7. 在验证集上评估\n",
    "# ------------------------------------------------\n",
    "# 用最优参数的模型预测验证集\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# 打印分类报告（包含精确率、召回率、F1值等）\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e7ff8",
   "metadata": {},
   "source": [
    "# 贝叶斯搜索BayesSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cbd6e0",
   "metadata": {},
   "source": [
    "**贝叶斯搜索BayesSearchCV** 是 scikit-optimize（skopt）库提供的基于贝叶斯优化的超参数搜索方法，相比 GridSearchCV 和 RandomizedSearchCV，它通过​​自适应参数采样​​更高效地找到最优解，特别适合​​计算成本高​​的模型调优。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce9253",
   "metadata": {},
   "source": [
    "贝叶斯搜索BayesSearchCV原理：\n",
    "1. **建立概率模型**：用高斯过程（Gaussian Process）或树形Parzen估计器（TPE）建模目标函数（如交叉验证得分）与超参数的关系。\n",
    "2. **迭代优化**：\n",
    "    - 根据已有参数组合的表现，预测哪些区域更可能包含最优解。\n",
    "    - 优先探索表现好或不确定性高的参数区域。\n",
    "3. **收敛**：经过多次迭代后，参数采样集中在最优解附近。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be06fb",
   "metadata": {},
   "source": [
    "## 贝叶斯搜索BayesSearchCV优缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f873d91",
   "metadata": {},
   "source": [
    "- 优点：\n",
    "    - 高效调参：通过自适应采样（如高斯过程或TPE）优先探索表现好的参数区域，比随机搜索/网格搜索更快收敛到最优解。\n",
    "    - 减少计算浪费：避免网格搜索的“盲目穷举”和随机搜索的“低效随机”，尤其适合训练成本高的模型（如深度学习、XGBoost）。\n",
    "- 缺点：\n",
    "    - 单次迭代成本高：每轮迭代需更新概率模型，计算开销比随机搜索大（适合“训练耗时 >> 搜索耗时”的场景）\n",
    "    - 对初始点敏感：若初始随机采样点质量差，可能陷入局部最优（可通过增加 n_iter 缓解）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170931c",
   "metadata": {},
   "source": [
    "## BayesSearchCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d832374",
   "metadata": {},
   "source": [
    "- `estimator`: 要被调参的模型对象\n",
    "- `search_spaces`: 参数空间字典，定义参数搜索空间\n",
    "- `n_iter`: 参数组合数量（越大越可能找到最优解，但计算成本越高）\n",
    "- `scoring`: 模型评估标准\n",
    "- `n_jobs`: 并行计算使用的 CPU 核心数\n",
    "    - n_jobs=1: 单线程\n",
    "    - n_jobs=-1: 使用全部 CPU 核心（推荐）\n",
    "- `cv`: 设置交叉验证方式\n",
    "    - None：默认 5 折交叉验证\n",
    "    - 整数：表示 K 折。如 cv=10表示十折\n",
    "    - 对象：KFold、StratifiedKFold（参考C04课程讲解）\n",
    "- `verbose`: 控制日志输出信息量\n",
    "    - 0: 不输出\n",
    "    - 1: 输出基本信息\n",
    "    - 2: 更详细（推荐用于调试）\n",
    "- `random_state`: 随机数种子（保证结果可复现）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfef44c",
   "metadata": {},
   "source": [
    "## 返回结果\n",
    "- `.best_params_`：最佳参数组合\n",
    "- `.best_score_`：最佳得分（交叉验证）\n",
    "- `.best_estimator_`：最优模型对象（如果 refit=True）\n",
    "- `.cv_results_`：包含所有搜索结果的详细信息字典，可转换为 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc624a",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7af774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始贝叶斯优化...\n",
      "优化完成！\n",
      "\n",
      "Best parameters: OrderedDict({'max_depth': 5, 'max_features': 0.7, 'min_samples_split': 4, 'n_estimators': 50})\n",
      "Best cross-val score: 0.9500\n",
      "\n",
      "测试集性能报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "参数组合:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.7, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.9, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.9, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.7, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.9, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.7, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.8, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.8, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.6, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'min_sam...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.1, 'min_sam...</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'min_sam...</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.5, 'min_sam...</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.1, 'min_sam...</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.3, 'min_sam...</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.4, 'min_sam...</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2, 'min_sam...</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.1, 'min_sam...</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score\n",
       "0   {'max_depth': 5, 'max_features': 0.7, 'min_sam...         0.950000\n",
       "2   {'max_depth': 5, 'max_features': 0.9, 'min_sam...         0.950000\n",
       "17  {'max_depth': 5, 'max_features': 0.6, 'min_sam...         0.950000\n",
       "5   {'max_depth': 7, 'max_features': 0.9, 'min_sam...         0.950000\n",
       "6   {'max_depth': 5, 'max_features': 0.7, 'min_sam...         0.950000\n",
       "7   {'max_depth': 5, 'max_features': 0.9, 'min_sam...         0.950000\n",
       "8   {'max_depth': 7, 'max_features': 0.7, 'min_sam...         0.950000\n",
       "9   {'max_depth': 3, 'max_features': 0.8, 'min_sam...         0.950000\n",
       "1   {'max_depth': 7, 'max_features': 0.8, 'min_sam...         0.950000\n",
       "11  {'max_depth': 7, 'max_features': 0.6, 'min_sam...         0.950000\n",
       "12  {'max_depth': 5, 'max_features': 0.8, 'min_sam...         0.950000\n",
       "13  {'max_depth': 5, 'max_features': 0.8, 'min_sam...         0.950000\n",
       "14  {'max_depth': 7, 'max_features': 0.1, 'min_sam...         0.941667\n",
       "18  {'max_depth': 7, 'max_features': 0.2, 'min_sam...         0.941667\n",
       "19  {'max_depth': 5, 'max_features': 0.5, 'min_sam...         0.941667\n",
       "15  {'max_depth': 5, 'max_features': 0.1, 'min_sam...         0.933333\n",
       "16  {'max_depth': 7, 'max_features': 0.3, 'min_sam...         0.933333\n",
       "4   {'max_depth': 7, 'max_features': 0.4, 'min_sam...         0.933333\n",
       "3   {'max_depth': 7, 'max_features': 0.2, 'min_sam...         0.933333\n",
       "10  {'max_depth': 3, 'max_features': 0.1, 'min_sam...         0.933333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from sklearn.ensemble import RandomForestClassifier  # 随机森林分类器\n",
    "from sklearn.datasets import load_iris  # 鸢尾花数据集\n",
    "from sklearn.model_selection import train_test_split  # 数据分割\n",
    "from sklearn.metrics import classification_report  # 分类评估报告\n",
    "from skopt import BayesSearchCV  # 贝叶斯优化搜索（需安装scikit-optimize）\n",
    "from skopt.space import Real, Integer, Categorical  # 参数空间定义\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息\n",
    "\n",
    "# 1. 加载数据\n",
    "# ------------------------------------------------\n",
    "# 使用sklearn自带的鸢尾花数据集（150个样本，4个特征，3个类别）\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target  # X是特征矩阵，y是目标标签\n",
    "\n",
    "# 2. 划分训练集和验证集\n",
    "# ------------------------------------------------\n",
    "# 随机拆分数据，验证集占20%，random_state保证每次运行结果一致\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. 定义贝叶斯搜索的参数空间\n",
    "param_space = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "}\n",
    "\n",
    "# 4. 初始化BayesSearchCV\n",
    "# ------------------------------------------------\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),  # 基础模型\n",
    "    search_spaces=param_space,  # 参数空间\n",
    "    n_iter=20,                  # 迭代次数（即参数评估次数）\n",
    "    cv=5,                       # 5折交叉验证\n",
    "    scoring='accuracy',         # 评估指标（准确率）\n",
    "    random_state=42,            # 保证结果可复现\n",
    "    n_jobs=-1,                  # 使用所有CPU核心\n",
    "    optimizer_kwargs={'base_estimator': 'GP'}  # 使用高斯过程建模目标函数\n",
    ")\n",
    "\n",
    "# 5. 执行贝叶斯优化\n",
    "# ------------------------------------------------\n",
    "print(\"开始贝叶斯优化...\")\n",
    "# 过程包含：\n",
    "# 1) 初始随机采样若干点\n",
    "# 2) 用高斯过程建模参数->得分关系\n",
    "# 3) 根据模型预测，选择最有潜力的新参数评估\n",
    "bayes_search.fit(X_train, y_train)\n",
    "print(\"优化完成！\")\n",
    "\n",
    "# 6. 输出最优结果\n",
    "# ------------------------------------------------\n",
    "print(\"\\nBest parameters:\", bayes_search.best_params_)  # 最佳参数组合\n",
    "print(\"Best cross-val score: {:.4f}\".format(bayes_search.best_score_))  # 最佳交叉验证得分\n",
    "\n",
    "# 7. 在测试集上评估\n",
    "# ------------------------------------------------\n",
    "y_pred = bayes_search.predict(X_test)\n",
    "print(\"\\n测试集性能报告:\")\n",
    "# 输出分类报告（精确率/召回率/F1值）\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. 查看所有尝试的参数组合（可选）\n",
    "# ------------------------------------------------\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(bayes_search.cv_results_)  # 转为DataFrame\n",
    "print(\"\\n参数组合:\")\n",
    "# 按得分排序\n",
    "results[['params', 'mean_test_score']].sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17cd510",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36c463",
   "metadata": {},
   "source": [
    "| 特性               | GridSearchCV                          | RandomizedSearchCV                     | BayesSearchCV                          |\n",
    "|--------------------|---------------------------------------|----------------------------------------|----------------------------------------|\n",
    "| 搜索策略           | 穷举所有参数组合                      | 随机采样参数组合                       | 基于概率模型自适应采样（如高斯过程）   |\n",
    "| 参数空间类型       | 仅离散（需显式列举）                  | 离散 + 连续（支持分布抽样）            | 离散 + 连续 + 混合（支持概率分布）      |\n",
    "| 计算效率           | ❌ 低效（参数组合数爆炸）             | ✅ 中等（通过 n_iter 控制）            | ✅✅ 高效（智能收敛，减少无效尝试）     |\n",
    "| 是否找到全局最优   | ✅ 在给定网格内保证最优               | ❌ 可能错过最优（依赖随机抽样）        | ⚠️ 接近最优（依赖初始点和迭代次数）    |\n",
    "| 并行化支持         | ✅ 支持（n_jobs）                     | ✅ 支持（n_jobs）                      | ✅ 支持（n_jobs）                       |\n",
    "| 实现库             | scikit-learn 内置                     | scikit-learn 内置                     | 需 scikit-optimize（非 sklearn 官方）  |\n",
    "| 最佳参数返回值     | best_params_                          | best_params_                          | best_params_                           |\n",
    "| 主要优点           | 结果确定性强                          | 适合高维参数空间                      | 计算资源利用率高，适合复杂参数交互     |\n",
    "| 主要缺点           | 计算成本高，不适合连续参数            | 结果可能不稳定                        | 单次迭代成本高，需额外依赖库           |\n",
    "| 典型应用场景       | 参数少（<5）且可穷举                  | 快速原型开发/中等规模调参             | 高计算成本模型（如深度学习、XGBoost）  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce0e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf383e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498ebf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "598px",
    "left": "22px",
    "top": "111.141px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
