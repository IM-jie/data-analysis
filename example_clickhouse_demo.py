#!/usr/bin/env python3
"""
ClickHouse KPIæ•°æ®åˆ†æåŠŸèƒ½æ¼”ç¤º
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºClickHouseåˆ†æåŠŸèƒ½
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from analysis.kpi_association_miner import KPIAssociationMiner, KPIAssociationAnomalyDetector
from analysis.kpi_anomaly_detector import KPIComprehensiveAnalyzer
from visualization.kpi_report_generator import KPIReportGenerator
from loguru import logger


class MockClickHouseConnector:
    """æ¨¡æ‹ŸClickHouseè¿æ¥å™¨ï¼Œç”¨äºæ¼”ç¤ºåŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡æ‹Ÿè¿æ¥å™¨"""
        self.data = self._create_mock_data()
        logger.info("æ¨¡æ‹ŸClickHouseè¿æ¥å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _create_mock_data(self) -> pd.DataFrame:
        """åˆ›å»ºæ¨¡æ‹Ÿçš„KPIæ•°æ®"""
        # åˆ›å»ºæ›´çœŸå®çš„KPIæ•°æ®
        departments = ['æŠ€æœ¯éƒ¨', 'äº§å“éƒ¨', 'è¿è¥éƒ¨', 'å¸‚åœºéƒ¨', 'é”€å”®éƒ¨']
        quarters = ['2025Q1', '2025Q2', '2025Q3', '2025Q4']
        
        data = []
        id_counter = 1
        
        for dept in departments:
            for quarter in quarters:
                # åŸºç¡€å€¼
                base_project_count = np.random.randint(8, 25)
                base_employee_count = np.random.randint(30, 120)
                base_test_case_count = np.random.randint(800, 2500)
                base_automated_test_count = np.random.randint(400, 1500)
                base_code_coverage = np.random.uniform(0.65, 0.92)
                base_bug_fix_rate = np.random.uniform(0.75, 0.96)
                base_delivery_rate = np.random.uniform(0.82, 0.98)
                base_customer_satisfaction = np.random.uniform(3.8, 4.6)
                
                # æ·»åŠ è¶‹åŠ¿å’Œç›¸å…³æ€§
                quarter_index = quarters.index(quarter)
                trend_factor = 1.0 + (quarter_index * 0.05)  # éšæ—¶é—´å¢é•¿
                
                # é¡¹ç›®æ•°é‡ä¸å‘˜å·¥æ•°é‡ç›¸å…³
                employee_factor = base_employee_count / 50
                project_count = int(base_project_count * trend_factor * (0.8 + 0.4 * employee_factor))
                
                # æµ‹è¯•ç”¨ä¾‹æ•°ä¸é¡¹ç›®æ•°é‡ç›¸å…³
                test_case_count = int(base_test_case_count * (1.0 + 0.3 * (project_count / 15 - 1)))
                
                # è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹æ•°ä¸æµ‹è¯•ç”¨ä¾‹æ•°ç›¸å…³
                automated_test_count = int(base_test_case_count * 0.6 * (1.0 + 0.2 * (test_case_count / 1500 - 1)))
                
                # ä»£ç è¦†ç›–ç‡ä¸è‡ªåŠ¨åŒ–æµ‹è¯•ç›¸å…³
                code_coverage = min(0.95, base_code_coverage * (1.0 + 0.1 * (automated_test_count / 1000 - 1)))
                
                # Bugä¿®å¤ç‡ä¸ä»£ç è¦†ç›–ç‡ç›¸å…³
                bug_fix_rate = min(0.98, base_bug_fix_rate * (1.0 + 0.05 * (code_coverage / 0.8 - 1)))
                
                # é¡¹ç›®äº¤ä»˜ç‡ä¸å‘˜å·¥æ•°é‡ç›¸å…³
                delivery_rate = min(0.99, base_delivery_rate * (1.0 + 0.03 * (employee_factor - 1)))
                
                # å®¢æˆ·æ»¡æ„åº¦ä¸äº¤ä»˜ç‡ç›¸å…³
                customer_satisfaction = min(5.0, base_customer_satisfaction * (1.0 + 0.02 * (delivery_rate / 0.9 - 1)))
                
                row = {
                    'id': id_counter,
                    'department_name': dept,
                    'quarter': quarter,
                    'project_count': project_count,
                    'employee_count': base_employee_count,
                    'test_case_count': test_case_count,
                    'automated_test_count': automated_test_count,
                    'code_coverage': round(code_coverage, 3),
                    'bug_fix_rate': round(bug_fix_rate, 3),
                    'delivery_rate': round(delivery_rate, 3),
                    'customer_satisfaction': round(customer_satisfaction, 3)
                }
                data.append(row)
                id_counter += 1
        
        return pd.DataFrame(data)
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        return True
    
    def get_databases(self) -> list:
        """è·å–æ•°æ®åº“åˆ—è¡¨"""
        return ['default', 'kpi_db', 'analytics']
    
    def get_tables(self) -> list:
        """è·å–è¡¨åˆ—è¡¨"""
        return ['kpi_data', 'department_metrics', 'project_analytics']
    
    def get_data_summary(self, table_name: str) -> dict:
        """è·å–æ•°æ®æ‘˜è¦"""
        return {
            'table_name': table_name,
            'database': 'default',
            'total_rows': len(self.data),
            'total_columns': len(self.data.columns),
            'numeric_columns': ['project_count', 'employee_count', 'test_case_count', 
                              'automated_test_count', 'code_coverage', 'bug_fix_rate', 
                              'delivery_rate', 'customer_satisfaction'],
            'string_columns': ['department_name', 'quarter'],
            'date_columns': [],
            'all_columns': list(self.data.columns)
        }
    
    def get_kpi_data(self, **kwargs) -> pd.DataFrame:
        """è·å–KPIæ•°æ®"""
        return self.data.copy()
    
    def get_department_kpi_data(self, department_name: str, **kwargs) -> pd.DataFrame:
        """è·å–éƒ¨é—¨KPIæ•°æ®"""
        return self.data[self.data['department_name'] == department_name].copy()
    
    def get_metric_trend_data(self, metric_name: str, **kwargs) -> pd.DataFrame:
        """è·å–æŒ‡æ ‡è¶‹åŠ¿æ•°æ®"""
        if metric_name not in self.data.columns:
            return pd.DataFrame()
        
        trend_data = self.data.groupby('quarter')[metric_name].agg(['mean', 'min', 'max', 'count']).reset_index()
        trend_data.columns = ['quarter', 'avg_value', 'min_value', 'max_value', 'data_count']
        return trend_data
    
    def get_correlation_data(self, metric_columns: list, **kwargs) -> pd.DataFrame:
        """è·å–ç›¸å…³æ€§æ•°æ®"""
        return self.data[['department_name', 'quarter'] + metric_columns].copy()
    
    def get_association_data(self, metric_columns: list, **kwargs) -> pd.DataFrame:
        """è·å–å…³è”å…³ç³»æ•°æ®"""
        return self.data[['department_name', 'quarter'] + metric_columns].copy()
    
    def close(self):
        """å…³é—­è¿æ¥"""
        logger.info("æ¨¡æ‹ŸClickHouseè¿æ¥å·²å…³é—­")


class MockClickHouseKPIAnalyzer:
    """æ¨¡æ‹ŸClickHouse KPIåˆ†æå™¨"""
    
    def __init__(self, connector):
        self.connector = connector
    
    def analyze_department_performance(self, department_name: str, **kwargs):
        """åˆ†æéƒ¨é—¨ç»©æ•ˆ"""
        dept_data = self.connector.get_department_kpi_data(department_name)
        
        if dept_data.empty:
            return {'error': f'æœªæ‰¾åˆ°éƒ¨é—¨ {department_name} çš„æ•°æ®'}
        
        results = {
            'department_name': department_name,
            'data_points': len(dept_data),
            'time_range': {
                'start': dept_data['quarter'].min(),
                'end': dept_data['quarter'].max()
            },
            'metrics_analysis': {}
        }
        
        # åˆ†ææ¯ä¸ªæŒ‡æ ‡
        metric_columns = ['project_count', 'employee_count', 'test_case_count', 
                         'automated_test_count', 'code_coverage', 'bug_fix_rate', 
                         'delivery_rate', 'customer_satisfaction']
        
        for metric in metric_columns:
            if metric in dept_data.columns:
                metric_data = dept_data[metric].dropna()
                if len(metric_data) > 0:
                    results['metrics_analysis'][metric] = {
                        'mean': float(metric_data.mean()),
                        'std': float(metric_data.std()),
                        'min': float(metric_data.min()),
                        'max': float(metric_data.max()),
                        'trend': self._calculate_trend(metric_data),
                        'anomalies': self._detect_anomalies(metric_data)
                    }
        
        return results
    
    def analyze_metric_correlations(self, metric_columns: list, **kwargs):
        """åˆ†ææŒ‡æ ‡ç›¸å…³æ€§"""
        corr_data = self.connector.get_correlation_data(metric_columns)
        
        if corr_data.empty:
            return {'error': 'æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®'}
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        metric_data = corr_data[metric_columns].dropna()
        correlation_matrix = metric_data.corr()
        
        # æ‰¾å‡ºå¼ºç›¸å…³æ€§
        strong_correlations = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_value = correlation_matrix.iloc[i, j]
                if abs(corr_value) > 0.7:  # å¼ºç›¸å…³æ€§é˜ˆå€¼
                    strong_correlations.append({
                        'metric1': correlation_matrix.columns[i],
                        'metric2': correlation_matrix.columns[j],
                        'correlation': float(corr_value)
                    })
        
        return {
            'correlation_matrix': correlation_matrix.to_dict(),
            'strong_correlations': strong_correlations,
            'data_points': len(metric_data)
        }
    
    def _calculate_trend(self, data: pd.Series) -> str:
        """è®¡ç®—è¶‹åŠ¿"""
        if len(data) < 2:
            return 'insufficient_data'
        
        x = np.arange(len(data))
        y = data.values
        slope = np.polyfit(x, y, 1)[0]
        
        if slope > 0.05:
            return 'increasing'
        elif slope < -0.05:
            return 'decreasing'
        else:
            return 'stable'
    
    def _detect_anomalies(self, data: pd.Series, threshold: float = 2.0) -> list:
        """æ£€æµ‹å¼‚å¸¸å€¼"""
        if len(data) < 3:
            return []
        
        mean = data.mean()
        std = data.std()
        
        if std == 0:
            return []
        
        z_scores = np.abs((data - mean) / std)
        anomalies = z_scores > threshold
        
        return data[anomalies].index.tolist()


def demo_1_basic_analysis():
    """æ¼”ç¤º1: åŸºç¡€åˆ†æ"""
    print("=" * 60)
    print("æ¼”ç¤º1: åŸºç¡€åˆ†æ")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¨¡æ‹Ÿè¿æ¥å™¨
    connector = MockClickHouseConnector()
    analyzer = MockClickHouseKPIAnalyzer(connector)
    
    # è·å–æ•°æ®æ‘˜è¦
    summary = connector.get_data_summary('kpi_data')
    print("æ•°æ®æ‘˜è¦:")
    print(f"  è¡¨å: {summary['table_name']}")
    print(f"  æ€»è¡Œæ•°: {summary['total_rows']}")
    print(f"  æ€»åˆ—æ•°: {summary['total_columns']}")
    print(f"  æ•°å€¼åˆ—: {summary['numeric_columns']}")
    
    # è·å–KPIæ•°æ®
    kpi_data = connector.get_kpi_data()
    print(f"\næ•°æ®å½¢çŠ¶: {kpi_data.shape}")
    print(f"æ•°æ®é¢„è§ˆ:")
    print(kpi_data.head())
    
    # è¿›è¡Œç»¼åˆåˆ†æ
    comprehensive_analyzer = KPIComprehensiveAnalyzer()
    analysis_results = comprehensive_analyzer.analyze_kpi_data(
        data=kpi_data,
        department_column='department_name',
        metric_columns=['project_count', 'employee_count', 'test_case_count', 
                       'automated_test_count', 'code_coverage', 'bug_fix_rate', 
                       'delivery_rate', 'customer_satisfaction'],
        time_columns=['quarter']
    )
    
    print("\nåˆ†æç»“æœæ‘˜è¦:")
    print(f"  å¼‚å¸¸æ£€æµ‹ç»“æœ: {len(analysis_results.get('anomaly_detection', {}).get('anomalies', []))} ä¸ªå¼‚å¸¸")
    print(f"  è¶‹åŠ¿åˆ†æç»“æœ: {len(analysis_results.get('trend_analysis', {}).get('trends', []))} ä¸ªè¶‹åŠ¿")
    
    connector.close()
    return True


def demo_2_department_analysis():
    """æ¼”ç¤º2: éƒ¨é—¨åˆ†æ"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤º2: éƒ¨é—¨åˆ†æ")
    print("=" * 60)
    
    connector = MockClickHouseConnector()
    analyzer = MockClickHouseKPIAnalyzer(connector)
    
    # åˆ†ææŠ€æœ¯éƒ¨
    results = analyzer.analyze_department_performance('æŠ€æœ¯éƒ¨')
    
    if 'error' in results:
        print(f"âœ— éƒ¨é—¨åˆ†æå¤±è´¥: {results['error']}")
        return False
    
    print("æŠ€æœ¯éƒ¨åˆ†æç»“æœ:")
    print(f"  æ•°æ®ç‚¹æ•°é‡: {results['data_points']}")
    print(f"  æ—¶é—´èŒƒå›´: {results['time_range']['start']} - {results['time_range']['end']}")
    
    # æ˜¾ç¤ºæŒ‡æ ‡åˆ†æ
    metrics_analysis = results.get('metrics_analysis', {})
    print(f"  åˆ†ææŒ‡æ ‡æ•°é‡: {len(metrics_analysis)}")
    
    for metric, analysis in metrics_analysis.items():
        print(f"\n  {metric}:")
        print(f"    å¹³å‡å€¼: {analysis['mean']:.3f}")
        print(f"    æ ‡å‡†å·®: {analysis['std']:.3f}")
        print(f"    è¶‹åŠ¿: {analysis['trend']}")
        print(f"    å¼‚å¸¸ç‚¹æ•°é‡: {len(analysis['anomalies'])}")
    
    connector.close()
    return True


def demo_3_correlation_analysis():
    """æ¼”ç¤º3: ç›¸å…³æ€§åˆ†æ"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤º3: ç›¸å…³æ€§åˆ†æ")
    print("=" * 60)
    
    connector = MockClickHouseConnector()
    analyzer = MockClickHouseKPIAnalyzer(connector)
    
    # åˆ†ææŒ‡æ ‡ç›¸å…³æ€§
    metric_columns = ['project_count', 'employee_count', 'test_case_count', 
                     'automated_test_count', 'code_coverage', 'bug_fix_rate']
    
    results = analyzer.analyze_metric_correlations(metric_columns)
    
    if 'error' in results:
        print(f"âœ— ç›¸å…³æ€§åˆ†æå¤±è´¥: {results['error']}")
        return False
    
    print("ç›¸å…³æ€§åˆ†æç»“æœ:")
    print(f"  æ•°æ®ç‚¹æ•°é‡: {results['data_points']}")
    
    # æ˜¾ç¤ºå¼ºç›¸å…³æ€§
    strong_correlations = results.get('strong_correlations', [])
    print(f"  å¼ºç›¸å…³æ€§å…³ç³»æ•°é‡: {len(strong_correlations)}")
    
    for i, corr in enumerate(strong_correlations[:5], 1):
        print(f"  {i}. {corr['metric1']} <-> {corr['metric2']}: {corr['correlation']:.3f}")
    
    connector.close()
    return True


def demo_4_association_mining():
    """æ¼”ç¤º4: å…³è”å…³ç³»æŒ–æ˜"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤º4: å…³è”å…³ç³»æŒ–æ˜")
    print("=" * 60)
    
    connector = MockClickHouseConnector()
    
    # è·å–å…³è”å…³ç³»æ•°æ®
    metric_columns = ['project_count', 'employee_count', 'test_case_count', 
                     'automated_test_count', 'code_coverage', 'bug_fix_rate']
    
    association_data = connector.get_association_data(metric_columns)
    
    if association_data.empty:
        print("âœ— æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
        return False
    
    # è¿›è¡Œå…³è”å…³ç³»æŒ–æ˜
    miner = KPIAssociationMiner()
    association_results = miner.discover_associations(
        data=association_data,
        metric_columns=metric_columns
    )
    
    print("å…³è”å…³ç³»æŒ–æ˜ç»“æœ:")
    print(f"  æ•°æ®å½¢çŠ¶: {association_data.shape}")
    
    # æ˜¾ç¤ºå…³è”å…³ç³»æ‘˜è¦
    summary = association_results.get('summary', {})
    print(f"  å¼ºç›¸å…³æ€§å…³ç³»: {summary.get('total_strong_correlations', 0)}")
    print(f"  å¼ºäº’ä¿¡æ¯å…³ç³»: {summary.get('total_strong_mi_relationships', 0)}")
    print(f"  å› æœå…³ç³»é“¾: {summary.get('total_causal_chains', 0)}")
    
    # æ˜¾ç¤ºå…³é”®æ´å¯Ÿ
    insights = summary.get('key_insights', [])
    if insights:
        print("\nå…³é”®æ´å¯Ÿ:")
        for i, insight in enumerate(insights[:3], 1):
            print(f"  {i}. {insight}")
    
    connector.close()
    return True


def demo_5_anomaly_detection():
    """æ¼”ç¤º5: å¼‚å¸¸æ£€æµ‹"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤º5: å¼‚å¸¸æ£€æµ‹")
    print("=" * 60)
    
    connector = MockClickHouseConnector()
    
    # æ£€æµ‹å¼‚å¸¸
    metrics = ['project_count', 'test_case_count', 'code_coverage']
    
    for metric in metrics:
        # è·å–æŒ‡æ ‡è¶‹åŠ¿æ•°æ®
        trend_data = connector.get_metric_trend_data(metric)
        
        if not trend_data.empty:
            # ç®€å•çš„å¼‚å¸¸æ£€æµ‹ï¼ˆåŸºäºå¹³å‡å€¼å’Œæ ‡å‡†å·®ï¼‰
            values = trend_data['avg_value']
            mean = values.mean()
            std = values.std()
            
            anomalies = []
            for i, value in enumerate(values):
                z_score = abs((value - mean) / std)
                if z_score > 2.0:  # å¼‚å¸¸é˜ˆå€¼
                    anomalies.append({
                        'quarter': trend_data.iloc[i]['quarter'],
                        'value': value,
                        'z_score': z_score
                    })
            
            print(f"\n{metric} å¼‚å¸¸æ£€æµ‹ç»“æœ:")
            print(f"  å¼‚å¸¸æ•°é‡: {len(anomalies)}")
            if anomalies:
                print("  å¼‚å¸¸æ•°æ®ç¤ºä¾‹:")
                for i, anomaly in enumerate(anomalies[:3], 1):
                    print(f"    {i}. å­£åº¦: {anomaly['quarter']}, "
                          f"å€¼: {anomaly['value']:.3f}, "
                          f"Z-score: {anomaly['z_score']:.3f}")
    
    connector.close()
    return True


def demo_6_data_export():
    """æ¼”ç¤º6: æ•°æ®å¯¼å‡º"""
    print("\n" + "=" * 60)
    print("æ¼”ç¤º6: æ•°æ®å¯¼å‡º")
    print("=" * 60)
    
    connector = MockClickHouseConnector()
    
    # å¯¼å‡ºæ•°æ®åˆ°Excel
    output_file = "mock_clickhouse_kpi_data.xlsx"
    kpi_data = connector.get_kpi_data()
    
    try:
        kpi_data.to_excel(output_file, index=False)
        print(f"âœ“ æ•°æ®å¯¼å‡ºæˆåŠŸ: {output_file}")
        print(f"âœ“ å¯¼å‡ºæ–‡ä»¶åŒ…å« {len(kpi_data)} è¡Œæ•°æ®")
        print(f"âœ“ å¯¼å‡ºæ–‡ä»¶åŒ…å« {len(kpi_data.columns)} åˆ—")
        
        # éªŒè¯å¯¼å‡ºæ–‡ä»¶
        if os.path.exists(output_file):
            df = pd.read_excel(output_file)
            print(f"âœ“ éªŒè¯æˆåŠŸï¼Œæ–‡ä»¶åŒ…å« {len(df)} è¡Œæ•°æ®")
        else:
            print("âœ— å¯¼å‡ºæ–‡ä»¶æœªæ‰¾åˆ°")
        
    except Exception as e:
        print(f"âœ— æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
    
    connector.close()
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ClickHouse KPIæ•°æ®åˆ†æåŠŸèƒ½æ¼”ç¤º")
    print("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºClickHouseåˆ†æåŠŸèƒ½")
    
    results = []
    
    try:
        # è¿è¡Œå„ä¸ªæ¼”ç¤º
        results.append(("åŸºç¡€åˆ†æ", demo_1_basic_analysis()))
        results.append(("éƒ¨é—¨åˆ†æ", demo_2_department_analysis()))
        results.append(("ç›¸å…³æ€§åˆ†æ", demo_3_correlation_analysis()))
        results.append(("å…³è”å…³ç³»æŒ–æ˜", demo_4_association_mining()))
        results.append(("å¼‚å¸¸æ£€æµ‹", demo_5_anomaly_detection()))
        results.append(("æ•°æ®å¯¼å‡º", demo_6_data_export()))
        
        # æ˜¾ç¤ºæ¼”ç¤ºç»“æœ
        print("\n" + "=" * 60)
        print("æ¼”ç¤ºç»“æœæ±‡æ€»")
        print("=" * 60)
        
        passed = 0
        total = len(results)
        
        for demo_name, success in results:
            status = "âœ“ é€šè¿‡" if success else "âœ— å¤±è´¥"
            print(f"{demo_name}: {status}")
            if success:
                passed += 1
        
        print(f"\næ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæ¼”ç¤ºé€šè¿‡")
        
        if passed == total:
            print("\nğŸ‰ æ‰€æœ‰ClickHouseåŠŸèƒ½æ¼”ç¤ºæˆåŠŸï¼")
            print("\nClickHouseåŠŸèƒ½ç‰¹ç‚¹:")
            print("1. âœ“ é«˜æ€§èƒ½æ•°æ®æŸ¥è¯¢ - æ”¯æŒå¤§è§„æ¨¡KPIæ•°æ®åˆ†æ")
            print("2. âœ“ å®æ—¶æ•°æ®å¤„ç† - æ”¯æŒå®æ—¶æŒ‡æ ‡ç›‘æ§")
            print("3. âœ“ å¤æ‚SQLæŸ¥è¯¢ - æ”¯æŒå¤æ‚çš„åˆ†ææŸ¥è¯¢")
            print("4. âœ“ æ•°æ®å¯¼å‡º - æ”¯æŒå¯¼å‡ºåˆ°Excelæ ¼å¼")
            print("5. âœ“ é›†æˆåˆ†æ - ä¸æ•°æ®æŒ–æ˜åŠŸèƒ½æ— ç¼é›†æˆ")
            
            print("\nå®é™…ä½¿ç”¨å»ºè®®:")
            print("- å®‰è£…å¹¶é…ç½®ClickHouseæ•°æ®åº“æœåŠ¡")
            print("- ä½¿ç”¨ --config å‚æ•°æŒ‡å®šClickHouseé…ç½®æ–‡ä»¶")
            print("- ä½¿ç”¨ --table å‚æ•°æŒ‡å®šè¦åˆ†æçš„è¡¨å")
            print("- ä½¿ç”¨ --action å‚æ•°é€‰æ‹©æ‰§è¡Œçš„æ“ä½œ")
            print("- ä½¿ç”¨ --metrics å‚æ•°æŒ‡å®šè¦åˆ†æçš„æŒ‡æ ‡åˆ—")
            print("- å®šæœŸå¤‡ä»½é‡è¦çš„KPIæ•°æ®")
            
            print("\nClickHouseå®‰è£…æŒ‡å—:")
            print("1. ä¸‹è½½ClickHouse: https://clickhouse.com/docs/en/install")
            print("2. å¯åŠ¨æœåŠ¡: sudo systemctl start clickhouse-server")
            print("3. åˆ›å»ºæ•°æ®åº“å’Œè¡¨")
            print("4. å¯¼å…¥KPIæ•°æ®")
            print("5. è¿è¡Œåˆ†æè„šæœ¬")
        else:
            print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæ¼”ç¤ºå¤±è´¥")
        
        # æ¸…ç†å¯¼å‡ºæ–‡ä»¶
        if os.path.exists("mock_clickhouse_kpi_data.xlsx"):
            os.remove("mock_clickhouse_kpi_data.xlsx")
            print("å·²æ¸…ç†å¯¼å‡ºæ–‡ä»¶")
        
    except Exception as e:
        logger.error(f"ClickHouseæ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
        print(f"\né”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…")


if __name__ == "__main__":
    main()
